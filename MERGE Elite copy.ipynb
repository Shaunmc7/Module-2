{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2 Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we load in the data and make it ready for NA and NLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Packages and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the two Scopus CSV data files \n",
    "scopus2022 = pd.read_csv('scopus 2022 2021.csv',  sep = ',')\n",
    "scopus = pd.read_csv('scopus.csv',  sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Appending the two data files \n",
    "data = scopus2022.append(scopus, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting an overview of the data\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting an overview of the data\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify data columns for Network Analysis\n",
    "data_NA = data[['Authors', 'Author(s) ID', 'Title', 'Year', 'Cited by', 'References', 'Source title', 'Authors with affiliations']]\n",
    "\n",
    "#Checking NA data\n",
    "data_NA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking NA data\n",
    "data_NA.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking missing author ID\n",
    "data_NA[data_NA['Author(s) ID'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping row with mising author ID\n",
    "data_NA.dropna(subset=['Author(s) ID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the authors that have been working on most titles. \n",
    "data_NA['Authors'].value_counts(ascending=False).nlargest(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping row with \"No author name available\"\n",
    "data_NA['Authors'] = data_NA['Authors'].replace('[No author name available]', ' ')\n",
    "data_NA['Authors'] = data_NA['Authors'].replace(' ', np.nan)\n",
    "data_NA.dropna(subset=['Authors'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking titles with most authors\n",
    "data_NA['Title'].value_counts(ascending=False).nlargest(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we look into networks between authors. The aim is to identify co-authorships and locate important autors as well as detecting communities.\n",
    "\n",
    "It is an undirecet network since we have authors working on papers together. Also, the nature of the network is bipartite as the nodes can be authors or papers. Hence, authors are connected if they have been working on the same paper. Furthermore, the network should not consist of self-loops, since the authors cannot co-author with themselves. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages and preparing data for Network Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling in 'not specified' for authors with missing values in 'authors with affiliations'\n",
    "data_NA['Authors with affiliations'] = data_NA['Authors with affiliations'].fillna('Not Specified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reset index after filling in 'authors with affiliations'\n",
    "data_NA_Aff = data_NA[\"Authors with affiliations\"].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split column 'Authors with affiliations' so that each author gets his/her own row\n",
    "data_NA_Aff[\"Authors with affiliations\"] = data_NA_Aff.loc[:,\"Authors with affiliations\"].apply(lambda x: x.split(\"; \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the data\n",
    "data_NA_Aff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the new rows\n",
    "data_NA_Aff = data_NA_Aff.explode([\"Authors with affiliations\"], ignore_index=True)\n",
    "data_NA_Aff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making new column for author name from the Authors with affiliations column\n",
    "data_NA_Aff['Authors'] = data_NA_Aff.loc[:,\"Authors with affiliations\"].apply(lambda x: x.split(\",\")[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_NA_Aff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a new column for affiliations from the Authors with affiliations column\n",
    "data_NA_Aff['Affiliations'] = data_NA_Aff.loc[:,\"Authors with affiliations\"].apply(lambda x: x.split(\", \")[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the data\n",
    "data_NA_Aff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change list to string for column Authors\n",
    "f = lambda x: ','.join(map(str, x)) if isinstance(x, list) else x\n",
    "data_NA_Aff['Authors'] = data_NA_Aff['Authors'].apply(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change list to string for column Affiliations\n",
    "f = lambda x: ','.join(map(str, x)) if isinstance(x, list) else x\n",
    "data_NA_Aff['Affiliations'] = data_NA_Aff['Affiliations'].apply(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop duplicate authors to prepare for merge\n",
    "data_NA_Aff['Authors'] = data_NA_Aff['Authors'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping empty values\n",
    "data_NA_Aff = data_NA_Aff.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reset index\n",
    "data_NA_Aff = data_NA_Aff.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping columns\n",
    "data_NA_Aff = data_NA_Aff.drop(columns=[\"level_0\", \"index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove comma to prepare for merge\n",
    "data_NA_Aff['Authors'] = data_NA_Aff['Authors'].str.replace(',', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Moving on to data set data_NA - split the author column so that each author for each paper get his/her own row\n",
    "data_NA[\"Authors\"] = data_NA.loc[:,\"Authors\"].apply(lambda x: x.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explode \n",
    "data_NA = data_NA.explode([\"Authors\"],ignore_index=True)\n",
    "data_NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing column Authors for merge\n",
    "for col in 'Authors':\n",
    "    data_NA['Authors'] = data_NA['Authors'].apply(lambda x : x[1:] if x.startswith(\" \") else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding a ID-number for each author \n",
    "data_NA['Author_ID'] = pd.factorize(data_NA['Authors'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging the data to get affiliation for each author \n",
    "data_NA_merge = pd.merge(data_NA, data_NA_Aff[['Authors', 'Affiliations']], on='Authors', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the merged data\n",
    "data_NA_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_NA_merge.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill in 'not specified when affiliations is empty\n",
    "data_NA_merge['Affiliations'] = data_NA_merge['Affiliations'].fillna('Not Specified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the merged data \n",
    "data_NA_merge.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Co-authorship network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we specify a network of co-authorships, specifying edges and nodes. The network shows which authors have been working on papers together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms import bipartite\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing packages for network analysis\n",
    "import networkx as nx\n",
    "import nxviz as nv\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "#Import the libraries and link to the bokeh backend\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "hv.extension('bokeh')\n",
    "from bokeh.plotting import show\n",
    "\n",
    "from community import community_louvain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Greating edges between authors working on the same title\n",
    "data_NA_select = data_NA_merge[['Authors', 'Author_ID', 'Title', 'Affiliations', 'Year', 'Source title']]\n",
    "edges = pd.merge(data_NA_select, data_NA_select, on='Title')\n",
    "\n",
    "#Removing self-loops\n",
    "edges = edges[edges.Author_ID_x != edges.Author_ID_y]\n",
    "\n",
    "#Checking the edges\n",
    "edges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grouping authors to aggregate muliple co-occurence and generating a weight. To see how often two autors have been working together\n",
    "edges = edges.groupby(['Author_ID_x', 'Author_ID_y']).size().reset_index()\n",
    "\n",
    "#Checking the edges\n",
    "edges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking how many times an author has been working together with the same co-author\n",
    "edges[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming the new column for weight\n",
    "edges.rename({0:'weight'}, axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the number of titles an author has been working on\n",
    "edges['Author_ID_x'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a list to keep authors that have been working on at least 3 papers\n",
    "list_au_xy = edges['Author_ID_y'].value_counts().reset_index()[edges['Author_ID_y'].value_counts().reset_index()['Author_ID_y'] > 2]['index'].to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specifying a new edgelist \n",
    "edgesy = edges[edges['Author_ID_y'].isin(list_au_xy)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgesy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgesy.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgesxy = edgesy[edgesy['Author_ID_x'].isin(list_au_xy)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgesxy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgesxy.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the number of edges\n",
    "len(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create network object from pandas edgelist\n",
    "G = nx.from_pandas_edgelist(edgesxy, source='Author_ID_x', target='Author_ID_y', edge_attr='weight', create_using=nx.Graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nodes - Creating node-attribute dictionary \n",
    "node_attributes = data_NA_select[['Author_ID', 'Authors']].set_index('Author_ID').drop_duplicates().to_dict('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.set_node_attributes(G, {G.degree(): 'degree'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.set_node_attributes(G, node_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the number of nodes\n",
    "len(G.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the number of edges\n",
    "len(G.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G.degree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subset the graph keeping only nodes with degree > 1\n",
    "G = nx.subgraph(G, [n for n,d in G.degree() if d > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(G.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(G.edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate centralities\n",
    "centrality_dgr = nx.degree_centrality(G)\n",
    "centrality_eig = nx.eigenvector_centrality_numpy(G, weight = 'weight')\n",
    "centrality_bet = nx.betweenness_centrality(G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting centralities as as attributes of the Graph\n",
    "nx.set_node_attributes(G, centrality_dgr, 'dgr')\n",
    "nx.set_node_attributes(G, centrality_eig, 'eig')\n",
    "nx.set_node_attributes(G, centrality_bet, 'bet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn Graph object to DataFrame\n",
    "nodes_df = pd.DataFrame.from_dict(dict(G.nodes(data=True)), orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking nodes_df\n",
    "nodes_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Degree Centrality\n",
    "Degree Centrality is a measure of how many ties a nodes has. So a author that have co-authored with more authors will have a higher centrality degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Closer look at degree centrality \n",
    "nodes_df.sort_values('dgr', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Eigenvector Centrality\n",
    "Eigenvector Centrality is a measure of the influence a node has on a network - it takes into account the centrality of the autors connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Closer look at eigenvector centrality \n",
    "nodes_df.sort_values('eig', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Betweenness Centrality \n",
    "Betweenness Centrality is a measure of how often a author are in the shortes path between two other authors. It has to do with information passing between others. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Closer look at betweennes centrality \n",
    "nodes_df.sort_values('bet', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating partitions\n",
    "partition = community_louvain.best_partition(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add to node attributes\n",
    "nx.set_node_attributes(G, partition, 'partition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the dataframe after adding the partition column\n",
    "nodes_df = pd.DataFrame.from_dict(dict(G.nodes(data=True)), orient='index')\n",
    "nodes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the 20 largest communities\n",
    "nodes_df.partition.value_counts()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the number of partition (communities)\n",
    "nodes_df.partition.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking out the people from the 10 largest communities to create a plot\n",
    "top10_com = nodes_df.partition.value_counts()[:10].index \n",
    "\n",
    "#Creating nodes for 10 largest communities\n",
    "top10_com_nodes = nodes_df[nodes_df['partition'].isin(top10_com)].index\n",
    "\n",
    "#Create a subgraph \n",
    "g_sub = nx.subgraph(G, top10_com_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dataframe of the top 10 communities \n",
    "nodes_df_top10 = nodes_df[nodes_df['partition'].isin(top10_com)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_df_top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking at the 5 most important autors within the communities based on eigenvector centrality\n",
    "top_authors = nodes_df_top10.groupby('partition')['eig'].nlargest(5).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding back ID's and Names \n",
    "top_authors.rename({'level_1':'Author_ID'}, axis=1, inplace=True)\n",
    "top_authors = pd.merge(top_authors, data_NA_select[['Authors','Author_ID']].drop_duplicates(), on='Author_ID', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation of Co-author network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving a file to work on in Gephi\n",
    "nx.write_gexf(G, \"fintech.gexf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Communities plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specifying central nodes for graph based on eigenvector \n",
    "top_central_nodes = nodes_df[nodes_df['eig'] > nodes_df['eig'].quantile(0.98)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST \n",
    "nodes_df_merge = pd.merge(nodes_df, data_NA_merge[['Authors', 'Year', 'Source title', 'Affiliations', 'Title']], on='Authors', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a subset graph\n",
    "g_sub = nx.subgraph(G, top_central_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and save a layout.\n",
    "g_layout = nx.layout.spring_layout(g_sub) \n",
    "g_plot = hv.Graph.from_networkx(g_sub, g_layout).opts(tools=['hover'], node_color='partition')\n",
    "labels = hv.Labels(g_plot.nodes, ['x', 'y'], 'Authors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries and link to the bokeh backend\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "hv.extension('bokeh')\n",
    "from bokeh.plotting import show\n",
    "kwargs = dict(width=800, height=800, xaxis=None, yaxis=None)\n",
    "opts.defaults(opts.Nodes(**kwargs), opts.Graph(**kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the plot\n",
    "from holoviews.operation.datashader import datashade, bundle_graph\n",
    "bundled = bundle_graph(g_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the plot\n",
    "show(hv.render(bundled * labels.opts(text_font_size='6pt', text_color='white', bgcolor='gray')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Community plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the default figure size\n",
    "defaults = dict(width=750, height=750, padding=0.1,\n",
    "                xaxis=None, yaxis=None)\n",
    "hv.opts.defaults(\n",
    "    opts.EdgePaths(**defaults), opts.Graph(**defaults), opts.Nodes(**defaults))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and save layout for centrality plots\n",
    "# G_layout = nx.layout.kamada_kawai_layout(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.set_node_attributes(G, partition, 'partition')\n",
    "\n",
    "# g_plot_par = hv.Graph.from_networkx(G, G_layout).opts(tools=['hover'],\n",
    "#                                                   node_color='partition', cmap=plt.cm.Set1,\n",
    "#                                                   legend_position='right')\n",
    "\n",
    "# show(hv.render(g_plot_par))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ead7228e3ce83e41bf70533ef6cb908cca47080070bf26203aecc408ed5f3ad8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
