{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHWjyxICD2T2"
      },
      "source": [
        "### All the packages that will be needed for natural language processing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyLDAvis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EycgdmyvEbFo",
        "outputId": "c3b6e257-24ad-49c7-a2cf-ea2fc7aef872"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyLDAvis\n",
            "  Downloading pyLDAvis-3.3.1.tar.gz (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 4.4 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.16.0)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.8.4)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (3.6.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (57.4.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.21.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (3.1.2)\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.2.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.7.3)\n",
            "Collecting funcy\n",
            "  Downloading funcy-1.17-py2.py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2022.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.0->pyLDAvis) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->pyLDAvis) (5.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.7/dist-packages (from jinja2->pyLDAvis) (2.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyLDAvis) (3.1.0)\n",
            "Building wheels for collected packages: pyLDAvis, sklearn\n",
            "  Building wheel for pyLDAvis (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyLDAvis: filename=pyLDAvis-3.3.1-py2.py3-none-any.whl size=136898 sha256=1cf8993bd3176ef9beefb1d8b350e42c9d71bb2ab8b1eea21c35808a8414f76f\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/21/f6/17bcf2667e8a68532ba2fbf6d5c72fdf4c7f7d9abfa4852d2f\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1310 sha256=3ba13e0a7b7856c4e7de20e3d55bb5b5a06988c6d0c7f2382adc5c96cf920eb2\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n",
            "Successfully built pyLDAvis sklearn\n",
            "Installing collected packages: sklearn, funcy, pyLDAvis\n",
            "Successfully installed funcy-1.17 pyLDAvis-3.3.1 sklearn-0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "|!pip install preprocessor\n",
        "!pip install eli5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        },
        "id": "ShPTIvuXEN1-",
        "outputId": "767c9795-22cf-4301-f077-11651a66ac23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting preprocessor\n",
            "  Downloading preprocessor-1.1.3.tar.gz (4.2 kB)\n",
            "Building wheels for collected packages: preprocessor\n",
            "  Building wheel for preprocessor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for preprocessor: filename=preprocessor-1.1.3-py3-none-any.whl size=4477 sha256=0761429259fd63a598b7f1e82a6342e3e1e96e421f8183c4cee5690f9e42379e\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/b7/36/aa37256db62b4bfd35a6f1b5536e9ba843f257b79dcbf3d5f1\n",
            "Successfully built preprocessor\n",
            "Installing collected packages: preprocessor\n",
            "Successfully installed preprocessor-1.1.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting eli5\n",
            "  Downloading eli5-0.13.0.tar.gz (216 kB)\n",
            "\u001b[K     |████████████████████████████████| 216 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>17.1.0 in /usr/local/lib/python3.7/dist-packages (from eli5) (22.1.0)\n",
            "Collecting jinja2>=3.0.0\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 51.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from eli5) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from eli5) (1.7.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from eli5) (1.15.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.7/dist-packages (from eli5) (1.0.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from eli5) (0.10.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from eli5) (0.8.10)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.7/dist-packages (from jinja2>=3.0.0->eli5) (2.0.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->eli5) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->eli5) (3.1.0)\n",
            "Building wheels for collected packages: eli5\n",
            "  Building wheel for eli5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for eli5: filename=eli5-0.13.0-py2.py3-none-any.whl size=107748 sha256=5a75b8b074863e76e47edcffff5981a0a4de79b037dbb6236347ac3ef9bf5ea2\n",
            "  Stored in directory: /root/.cache/pip/wheels/cc/3c/96/3ead31a8e6c20fc0f1a707fde2e05d49a80b1b4b30096573be\n",
            "Successfully built eli5\n",
            "Installing collected packages: jinja2, eli5\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 2.11.3\n",
            "    Uninstalling Jinja2-2.11.3:\n",
            "      Successfully uninstalled Jinja2-2.11.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "flask 1.1.4 requires Jinja2<3.0,>=2.10.1, but you have jinja2 3.1.2 which is incompatible.\u001b[0m\n",
            "Successfully installed eli5-0.13.0 jinja2-3.1.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "jinja2"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0y4qSrKID2T7",
        "outputId": "3c7523eb-0b81-486d-a1f5-d6af33383516"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/past/types/oldstr.py:5: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
            "  from collections import Iterable\n"
          ]
        }
      ],
      "source": [
        "import string\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from spacy.lang.en import English\n",
        "from sklearn.base import TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import preprocessor as prepro # text prepro\n",
        "import tqdm #progress bar\n",
        "from gensim.models import LdaModel, CoherenceModel\n",
        "from gensim import corpora\n",
        "import seaborn as sns\n",
        "from imblearn.over_sampling import SMOTE\n",
        "SMOTE = SMOTE()\n",
        "import spacy #spacy for quick language prepro\n",
        "nlp = spacy.load('en_core_web_sm') #instantiating English module\n",
        "import scipy.sparse as ss\n",
        "\n",
        "# sampling, splitting\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# loading ML libraries\n",
        "from sklearn.pipeline import make_pipeline #pipeline creation\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer #transforms text to sparse matrix\n",
        "from sklearn.linear_model import LogisticRegression #Logit model\n",
        "from sklearn.metrics import classification_report #that's self explanatory\n",
        "from sklearn.decomposition import TruncatedSVD #dimensionality reduction\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import altair as alt #viz\n",
        "\n",
        "#explainability\n",
        "import eli5\n",
        "from eli5.lime import TextExplainer\n",
        "\n",
        "# topic modeling\n",
        "\n",
        "from gensim.corpora.dictionary import Dictionary # Import the dictionary builder\n",
        "from gensim.models import LdaMulticore # we'll use the faster multicore version of LDA\n",
        "\n",
        "# Import pyLDAvis\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models as gensimvis\n",
        "\n",
        "%matplotlib inline\n",
        "pyLDAvis.enable_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGXbQMWtD2T9"
      },
      "outputs": [],
      "source": [
        "# prepro settings\n",
        "# This is prob not relevant, since it has to do with tweets? \n",
        "# prepro.set_options(prepro.OPT.URL, prepro.OPT.NUMBER, prepro.OPT.RESERVED, prepro.OPT.MENTION, prepro.OPT.SMILEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcs7Hcz_D2T-"
      },
      "source": [
        "### Loading and appending the datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWmzmswAD2T_"
      },
      "outputs": [],
      "source": [
        "scopus2022 = pd.read_csv('/content/scopus 2022 2021.csv',  sep = ',')\n",
        "scopus = pd.read_csv('/content/scopus.csv',  sep = ',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYEhZ0f-D2T_"
      },
      "outputs": [],
      "source": [
        "data = scopus2022.append(scopus, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "knEto1MsD2UA",
        "outputId": "d85d89c7-00c9-4cda-d36c-b26a1d683d8b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                Authors  \\\n",
              "0                                     Yang T., Zhang X.   \n",
              "1                             Wang X., Wang Y., Zhao Y.   \n",
              "2                       Dzandu M.D., Hanu C., Amegbe H.   \n",
              "3                              Grassi L., Fantaccini S.   \n",
              "4                    DeFusco A.A., Tang H., Yannelis C.   \n",
              "...                                                 ...   \n",
              "3395                                        Fayard E.H.   \n",
              "3396                Dassanayake M.M.K., Tilakarathne C.   \n",
              "3397                                          Hao H.-N.   \n",
              "3398                                 Ma Z.-X., Zhang W.   \n",
              "3399  Danial S.N., Noor S.R., Usmani B.A., Zaidi S.J.H.   \n",
              "\n",
              "                                          Author(s) ID  \\\n",
              "0                             57907798100;56342888200;   \n",
              "1                 57193015825;57901727900;57901783600;   \n",
              "2                 56590001600;57201152816;57194904537;   \n",
              "3                             57192656409;57895835500;   \n",
              "4                 57193852071;57890330600;55413678100;   \n",
              "...                                                ...   \n",
              "3395                                      35072693600;   \n",
              "3396                          57221353725;55762978100;   \n",
              "3397                                      36617357100;   \n",
              "3398                          55479146300;56621528900;   \n",
              "3399  24823887800;24825002200;26666352700;57549810600;   \n",
              "\n",
              "                                                  Title  Year  \\\n",
              "0     FinTech adoption and financial inclusion: Evid...  2022   \n",
              "1     Financial permeation and rural poverty reducti...  2022   \n",
              "2     Gamification of mobile money payment for gener...  2022   \n",
              "3     An overview of Fintech applications to solve t...  2022   \n",
              "4     Measuring the welfare cost of asymmetric infor...  2022   \n",
              "...                                                 ...   ...   \n",
              "3395                              ACC pressure cleaning  2010   \n",
              "3396  Predicting trading signals of Sri Lankan stock...  2010   \n",
              "3397  Notice of Retraction: Short-term forecasting o...  2010   \n",
              "3398  Notice of Retraction: An discrimination resear...  2010   \n",
              "3399  A dynamical system and neural network perspect...  2008   \n",
              "\n",
              "                                           Source title   Volume Issue  \\\n",
              "0                        Journal of Banking and Finance      145   NaN   \n",
              "1                                 China Economic Review       76   NaN   \n",
              "2           Technological Forecasting and Social Change      185   NaN   \n",
              "3                                  Financial Innovation        8     1   \n",
              "4                        Journal of Financial Economics      146     3   \n",
              "...                                                 ...      ...   ...   \n",
              "3395           Power Engineering (Barrington, Illinois)      114     5   \n",
              "3396  Technological Developments in Networking, Educ...      NaN   NaN   \n",
              "3397  Proceedings - 2010 6th International Conferenc...        4   NaN   \n",
              "3398  ICAMS 2010 - Proceedings of 2010 IEEE Internat...        3   NaN   \n",
              "3399  Communications in Computer and Information Sci...  20 CCIS   NaN   \n",
              "\n",
              "     Art. No. Page start Page end  ...                       ISBN  CODEN  \\\n",
              "0      106668        NaN      NaN  ...                        NaN  JBFID   \n",
              "1      101863        NaN      NaN  ...                        NaN    NaN   \n",
              "2      122049        NaN      NaN  ...                        NaN    NaN   \n",
              "3          84        NaN      NaN  ...                        NaN    NaN   \n",
              "4         NaN        821    840.0  ...                        NaN  JFECD   \n",
              "...       ...        ...      ...  ...                        ...    ...   \n",
              "3395      NaN         22      NaN  ...                        NaN  POENA   \n",
              "3396      NaN        269      273  ...              9789048191505    NaN   \n",
              "3397  5584528       1838     1841  ...              9781424459612    NaN   \n",
              "3398  5553273        116      119  ...              9781424469291    NaN   \n",
              "3399      NaN         88       99  ...  3540898522; 9783540898528    NaN   \n",
              "\n",
              "     PubMed ID Language of Original Document  \\\n",
              "0          NaN                       English   \n",
              "1          NaN                       English   \n",
              "2          NaN                       English   \n",
              "3          NaN                       English   \n",
              "4          NaN                       English   \n",
              "...        ...                           ...   \n",
              "3395       NaN                       English   \n",
              "3396       NaN                       English   \n",
              "3397       NaN                       English   \n",
              "3398       NaN                       English   \n",
              "3399       NaN                       English   \n",
              "\n",
              "                             Abbreviated Source Title     Document Type  \\\n",
              "0                                    J. Bank. Financ.           Article   \n",
              "1                                    China Econ. Rev.           Article   \n",
              "2                      Technol. Forecast. Soc. Change           Article   \n",
              "3                                    Financial Innov.           Article   \n",
              "4                                    J. Financ. Econ.           Article   \n",
              "...                                               ...               ...   \n",
              "3395                        Power Eng. Barrington Ill      Short Survey   \n",
              "3396           Technol. Dev. Networking, Educ. Autom.  Conference Paper   \n",
              "3397            Proc. - Int. Conf. Nat. Comput., ICNC         Retracted   \n",
              "3398  ICAMS - Proc. IEEE Int. Conf. Adv. Manage. Sci.         Retracted   \n",
              "3399                       Commun. Comput. Info. Sci.  Conference Paper   \n",
              "\n",
              "     Publication Stage                          Open Access  Source  \\\n",
              "0                Final                                  NaN  Scopus   \n",
              "1                Final                                  NaN  Scopus   \n",
              "2                Final  All Open Access, Hybrid Gold, Green  Scopus   \n",
              "3                Final         All Open Access, Gold, Green  Scopus   \n",
              "4                Final                                  NaN  Scopus   \n",
              "...                ...                                  ...     ...   \n",
              "3395             Final                                  NaN  Scopus   \n",
              "3396             Final                                  NaN  Scopus   \n",
              "3397             Final                                  NaN  Scopus   \n",
              "3398             Final                                  NaN  Scopus   \n",
              "3399             Final                                  NaN  Scopus   \n",
              "\n",
              "                     EID  \n",
              "0     2-s2.0-85138806241  \n",
              "1     2-s2.0-85138589769  \n",
              "2     2-s2.0-85138450268  \n",
              "3     2-s2.0-85138286241  \n",
              "4     2-s2.0-85138101180  \n",
              "...                  ...  \n",
              "3395  2-s2.0-77953829082  \n",
              "3396  2-s2.0-84878897261  \n",
              "3397  2-s2.0-78149350510  \n",
              "3398  2-s2.0-77957273781  \n",
              "3399  2-s2.0-85099426338  \n",
              "\n",
              "[3400 rows x 54 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-96fdcd77-f4dc-4d6c-ab61-a305a3d232a7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Authors</th>\n",
              "      <th>Author(s) ID</th>\n",
              "      <th>Title</th>\n",
              "      <th>Year</th>\n",
              "      <th>Source title</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Issue</th>\n",
              "      <th>Art. No.</th>\n",
              "      <th>Page start</th>\n",
              "      <th>Page end</th>\n",
              "      <th>...</th>\n",
              "      <th>ISBN</th>\n",
              "      <th>CODEN</th>\n",
              "      <th>PubMed ID</th>\n",
              "      <th>Language of Original Document</th>\n",
              "      <th>Abbreviated Source Title</th>\n",
              "      <th>Document Type</th>\n",
              "      <th>Publication Stage</th>\n",
              "      <th>Open Access</th>\n",
              "      <th>Source</th>\n",
              "      <th>EID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Yang T., Zhang X.</td>\n",
              "      <td>57907798100;56342888200;</td>\n",
              "      <td>FinTech adoption and financial inclusion: Evid...</td>\n",
              "      <td>2022</td>\n",
              "      <td>Journal of Banking and Finance</td>\n",
              "      <td>145</td>\n",
              "      <td>NaN</td>\n",
              "      <td>106668</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>JBFID</td>\n",
              "      <td>NaN</td>\n",
              "      <td>English</td>\n",
              "      <td>J. Bank. Financ.</td>\n",
              "      <td>Article</td>\n",
              "      <td>Final</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Scopus</td>\n",
              "      <td>2-s2.0-85138806241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Wang X., Wang Y., Zhao Y.</td>\n",
              "      <td>57193015825;57901727900;57901783600;</td>\n",
              "      <td>Financial permeation and rural poverty reducti...</td>\n",
              "      <td>2022</td>\n",
              "      <td>China Economic Review</td>\n",
              "      <td>76</td>\n",
              "      <td>NaN</td>\n",
              "      <td>101863</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>English</td>\n",
              "      <td>China Econ. Rev.</td>\n",
              "      <td>Article</td>\n",
              "      <td>Final</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Scopus</td>\n",
              "      <td>2-s2.0-85138589769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Dzandu M.D., Hanu C., Amegbe H.</td>\n",
              "      <td>56590001600;57201152816;57194904537;</td>\n",
              "      <td>Gamification of mobile money payment for gener...</td>\n",
              "      <td>2022</td>\n",
              "      <td>Technological Forecasting and Social Change</td>\n",
              "      <td>185</td>\n",
              "      <td>NaN</td>\n",
              "      <td>122049</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>English</td>\n",
              "      <td>Technol. Forecast. Soc. Change</td>\n",
              "      <td>Article</td>\n",
              "      <td>Final</td>\n",
              "      <td>All Open Access, Hybrid Gold, Green</td>\n",
              "      <td>Scopus</td>\n",
              "      <td>2-s2.0-85138450268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Grassi L., Fantaccini S.</td>\n",
              "      <td>57192656409;57895835500;</td>\n",
              "      <td>An overview of Fintech applications to solve t...</td>\n",
              "      <td>2022</td>\n",
              "      <td>Financial Innovation</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>84</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>English</td>\n",
              "      <td>Financial Innov.</td>\n",
              "      <td>Article</td>\n",
              "      <td>Final</td>\n",
              "      <td>All Open Access, Gold, Green</td>\n",
              "      <td>Scopus</td>\n",
              "      <td>2-s2.0-85138286241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>DeFusco A.A., Tang H., Yannelis C.</td>\n",
              "      <td>57193852071;57890330600;55413678100;</td>\n",
              "      <td>Measuring the welfare cost of asymmetric infor...</td>\n",
              "      <td>2022</td>\n",
              "      <td>Journal of Financial Economics</td>\n",
              "      <td>146</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>821</td>\n",
              "      <td>840.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>JFECD</td>\n",
              "      <td>NaN</td>\n",
              "      <td>English</td>\n",
              "      <td>J. Financ. Econ.</td>\n",
              "      <td>Article</td>\n",
              "      <td>Final</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Scopus</td>\n",
              "      <td>2-s2.0-85138101180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3395</th>\n",
              "      <td>Fayard E.H.</td>\n",
              "      <td>35072693600;</td>\n",
              "      <td>ACC pressure cleaning</td>\n",
              "      <td>2010</td>\n",
              "      <td>Power Engineering (Barrington, Illinois)</td>\n",
              "      <td>114</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>22</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>POENA</td>\n",
              "      <td>NaN</td>\n",
              "      <td>English</td>\n",
              "      <td>Power Eng. Barrington Ill</td>\n",
              "      <td>Short Survey</td>\n",
              "      <td>Final</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Scopus</td>\n",
              "      <td>2-s2.0-77953829082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3396</th>\n",
              "      <td>Dassanayake M.M.K., Tilakarathne C.</td>\n",
              "      <td>57221353725;55762978100;</td>\n",
              "      <td>Predicting trading signals of Sri Lankan stock...</td>\n",
              "      <td>2010</td>\n",
              "      <td>Technological Developments in Networking, Educ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>269</td>\n",
              "      <td>273</td>\n",
              "      <td>...</td>\n",
              "      <td>9789048191505</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>English</td>\n",
              "      <td>Technol. Dev. Networking, Educ. Autom.</td>\n",
              "      <td>Conference Paper</td>\n",
              "      <td>Final</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Scopus</td>\n",
              "      <td>2-s2.0-84878897261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3397</th>\n",
              "      <td>Hao H.-N.</td>\n",
              "      <td>36617357100;</td>\n",
              "      <td>Notice of Retraction: Short-term forecasting o...</td>\n",
              "      <td>2010</td>\n",
              "      <td>Proceedings - 2010 6th International Conferenc...</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5584528</td>\n",
              "      <td>1838</td>\n",
              "      <td>1841</td>\n",
              "      <td>...</td>\n",
              "      <td>9781424459612</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>English</td>\n",
              "      <td>Proc. - Int. Conf. Nat. Comput., ICNC</td>\n",
              "      <td>Retracted</td>\n",
              "      <td>Final</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Scopus</td>\n",
              "      <td>2-s2.0-78149350510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3398</th>\n",
              "      <td>Ma Z.-X., Zhang W.</td>\n",
              "      <td>55479146300;56621528900;</td>\n",
              "      <td>Notice of Retraction: An discrimination resear...</td>\n",
              "      <td>2010</td>\n",
              "      <td>ICAMS 2010 - Proceedings of 2010 IEEE Internat...</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5553273</td>\n",
              "      <td>116</td>\n",
              "      <td>119</td>\n",
              "      <td>...</td>\n",
              "      <td>9781424469291</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>English</td>\n",
              "      <td>ICAMS - Proc. IEEE Int. Conf. Adv. Manage. Sci.</td>\n",
              "      <td>Retracted</td>\n",
              "      <td>Final</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Scopus</td>\n",
              "      <td>2-s2.0-77957273781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3399</th>\n",
              "      <td>Danial S.N., Noor S.R., Usmani B.A., Zaidi S.J.H.</td>\n",
              "      <td>24823887800;24825002200;26666352700;57549810600;</td>\n",
              "      <td>A dynamical system and neural network perspect...</td>\n",
              "      <td>2008</td>\n",
              "      <td>Communications in Computer and Information Sci...</td>\n",
              "      <td>20 CCIS</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>88</td>\n",
              "      <td>99</td>\n",
              "      <td>...</td>\n",
              "      <td>3540898522; 9783540898528</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>English</td>\n",
              "      <td>Commun. Comput. Info. Sci.</td>\n",
              "      <td>Conference Paper</td>\n",
              "      <td>Final</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Scopus</td>\n",
              "      <td>2-s2.0-85099426338</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3400 rows × 54 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-96fdcd77-f4dc-4d6c-ab61-a305a3d232a7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-96fdcd77-f4dc-4d6c-ab61-a305a3d232a7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-96fdcd77-f4dc-4d6c-ab61-a305a3d232a7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQN6X2TfD2UB",
        "outputId": "17a6cdab-1bc8-4c3b-a53b-ea87c8f20c34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3400 entries, 0 to 3399\n",
            "Data columns (total 54 columns):\n",
            " #   Column                         Non-Null Count  Dtype  \n",
            "---  ------                         --------------  -----  \n",
            " 0   Authors                        3400 non-null   object \n",
            " 1   Author(s) ID                   3399 non-null   object \n",
            " 2   Title                          3400 non-null   object \n",
            " 3   Year                           3400 non-null   int64  \n",
            " 4   Source title                   3400 non-null   object \n",
            " 5   Volume                         2320 non-null   object \n",
            " 6   Issue                          1426 non-null   object \n",
            " 7   Art. No.                       1051 non-null   object \n",
            " 8   Page start                     2336 non-null   object \n",
            " 9   Page end                       2326 non-null   object \n",
            " 10  Page count                     38 non-null     float64\n",
            " 11  Cited by                       2164 non-null   float64\n",
            " 12  DOI                            2972 non-null   object \n",
            " 13  Link                           3400 non-null   object \n",
            " 14  Affiliations                   3305 non-null   object \n",
            " 15  Authors with affiliations      3342 non-null   object \n",
            " 16  Abstract                       3400 non-null   object \n",
            " 17  Author Keywords                2781 non-null   object \n",
            " 18  Index Keywords                 1616 non-null   object \n",
            " 19  Molecular Sequence Numbers     0 non-null      float64\n",
            " 20  Chemicals/CAS                  4 non-null      object \n",
            " 21  Tradenames                     0 non-null      float64\n",
            " 22  Manufacturers                  0 non-null      float64\n",
            " 23  Funding Details                827 non-null    object \n",
            " 24  Funding Text 1                 1039 non-null   object \n",
            " 25  Funding Text 2                 141 non-null    object \n",
            " 26  Funding Text 3                 7 non-null      object \n",
            " 27  Funding Text 4                 1 non-null      object \n",
            " 28  Funding Text 5                 1 non-null      object \n",
            " 29  Funding Text 6                 1 non-null      object \n",
            " 30  Funding Text 7                 1 non-null      object \n",
            " 31  Funding Text 8                 0 non-null      float64\n",
            " 32  Funding Text 9                 0 non-null      float64\n",
            " 33  Funding Text 10                0 non-null      float64\n",
            " 34  References                     3212 non-null   object \n",
            " 35  Correspondence Address         2354 non-null   object \n",
            " 36  Editors                        491 non-null    object \n",
            " 37  Sponsors                       319 non-null    object \n",
            " 38  Publisher                      3394 non-null   object \n",
            " 39  Conference name                1063 non-null   object \n",
            " 40  Conference date                1062 non-null   object \n",
            " 41  Conference location            3 non-null      object \n",
            " 42  Conference code                1065 non-null   float64\n",
            " 43  ISSN                           2540 non-null   object \n",
            " 44  ISBN                           1174 non-null   object \n",
            " 45  CODEN                          276 non-null    object \n",
            " 46  PubMed ID                      36 non-null     float64\n",
            " 47  Language of Original Document  3400 non-null   object \n",
            " 48  Abbreviated Source Title       3396 non-null   object \n",
            " 49  Document Type                  3400 non-null   object \n",
            " 50  Publication Stage              3400 non-null   object \n",
            " 51  Open Access                    1097 non-null   object \n",
            " 52  Source                         3400 non-null   object \n",
            " 53  EID                            3400 non-null   object \n",
            "dtypes: float64(10), int64(1), object(43)\n",
            "memory usage: 1.4+ MB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "YCYShS4LD2UC",
        "outputId": "5d0a5975-1205-47ac-8686-0662dddb61ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           Authors              Author(s) ID         Title  \\\n",
              "count                         3400                      3399          3400   \n",
              "unique                        3167                      3156          3389   \n",
              "top     [No author name available]  [No author id available]  Introduction   \n",
              "freq                            58                        58             4   \n",
              "\n",
              "                                          Source title Volume Issue Art. No.  \\\n",
              "count                                             3400   2320  1426     1051   \n",
              "unique                                            1455    495    81     1023   \n",
              "top     ACM International Conference Proceeding Series      8     1        8   \n",
              "freq                                                93     95   322        4   \n",
              "\n",
              "       Page start Page end                         DOI  ...      ISSN  \\\n",
              "count        2336     2326                        2972  ...      2540   \n",
              "unique       1013     1369                        2969  ...       949   \n",
              "top             1       20  10.1142/9789811235825_0003  ...  21945357   \n",
              "freq          158       11                           2  ...        53   \n",
              "\n",
              "                                ISBN  CODEN Language of Original Document  \\\n",
              "count                           1174    276                          3400   \n",
              "unique                           821    124                             4   \n",
              "top     9781799832591; 9781799832577  JEBUD                       English   \n",
              "freq                              15     15                          3395   \n",
              "\n",
              "         Abbreviated Source Title Document Type Publication Stage  \\\n",
              "count                        3396          3400              3400   \n",
              "unique                       1429            13                 2   \n",
              "top     ACM Int. Conf. Proc. Ser.       Article             Final   \n",
              "freq                           93          1770              3241   \n",
              "\n",
              "                  Open Access  Source                 EID  \n",
              "count                    1097    3400                3400  \n",
              "unique                      7       1                3400  \n",
              "top     All Open Access, Gold  Scopus  2-s2.0-85138806241  \n",
              "freq                      278    3400                   1  \n",
              "\n",
              "[4 rows x 43 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-12a7531f-5896-4a5d-8fa6-32e7a083ce3e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Authors</th>\n",
              "      <th>Author(s) ID</th>\n",
              "      <th>Title</th>\n",
              "      <th>Source title</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Issue</th>\n",
              "      <th>Art. No.</th>\n",
              "      <th>Page start</th>\n",
              "      <th>Page end</th>\n",
              "      <th>DOI</th>\n",
              "      <th>...</th>\n",
              "      <th>ISSN</th>\n",
              "      <th>ISBN</th>\n",
              "      <th>CODEN</th>\n",
              "      <th>Language of Original Document</th>\n",
              "      <th>Abbreviated Source Title</th>\n",
              "      <th>Document Type</th>\n",
              "      <th>Publication Stage</th>\n",
              "      <th>Open Access</th>\n",
              "      <th>Source</th>\n",
              "      <th>EID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>3400</td>\n",
              "      <td>3399</td>\n",
              "      <td>3400</td>\n",
              "      <td>3400</td>\n",
              "      <td>2320</td>\n",
              "      <td>1426</td>\n",
              "      <td>1051</td>\n",
              "      <td>2336</td>\n",
              "      <td>2326</td>\n",
              "      <td>2972</td>\n",
              "      <td>...</td>\n",
              "      <td>2540</td>\n",
              "      <td>1174</td>\n",
              "      <td>276</td>\n",
              "      <td>3400</td>\n",
              "      <td>3396</td>\n",
              "      <td>3400</td>\n",
              "      <td>3400</td>\n",
              "      <td>1097</td>\n",
              "      <td>3400</td>\n",
              "      <td>3400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>3167</td>\n",
              "      <td>3156</td>\n",
              "      <td>3389</td>\n",
              "      <td>1455</td>\n",
              "      <td>495</td>\n",
              "      <td>81</td>\n",
              "      <td>1023</td>\n",
              "      <td>1013</td>\n",
              "      <td>1369</td>\n",
              "      <td>2969</td>\n",
              "      <td>...</td>\n",
              "      <td>949</td>\n",
              "      <td>821</td>\n",
              "      <td>124</td>\n",
              "      <td>4</td>\n",
              "      <td>1429</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>3400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>[No author name available]</td>\n",
              "      <td>[No author id available]</td>\n",
              "      <td>Introduction</td>\n",
              "      <td>ACM International Conference Proceeding Series</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>10.1142/9789811235825_0003</td>\n",
              "      <td>...</td>\n",
              "      <td>21945357</td>\n",
              "      <td>9781799832591; 9781799832577</td>\n",
              "      <td>JEBUD</td>\n",
              "      <td>English</td>\n",
              "      <td>ACM Int. Conf. Proc. Ser.</td>\n",
              "      <td>Article</td>\n",
              "      <td>Final</td>\n",
              "      <td>All Open Access, Gold</td>\n",
              "      <td>Scopus</td>\n",
              "      <td>2-s2.0-85138806241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>58</td>\n",
              "      <td>58</td>\n",
              "      <td>4</td>\n",
              "      <td>93</td>\n",
              "      <td>95</td>\n",
              "      <td>322</td>\n",
              "      <td>4</td>\n",
              "      <td>158</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>53</td>\n",
              "      <td>15</td>\n",
              "      <td>15</td>\n",
              "      <td>3395</td>\n",
              "      <td>93</td>\n",
              "      <td>1770</td>\n",
              "      <td>3241</td>\n",
              "      <td>278</td>\n",
              "      <td>3400</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4 rows × 43 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-12a7531f-5896-4a5d-8fa6-32e7a083ce3e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-12a7531f-5896-4a5d-8fa6-32e7a083ce3e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-12a7531f-5896-4a5d-8fa6-32e7a083ce3e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "data.describe(include='object')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYzDPh3DD2UC",
        "outputId": "10e9ec8f-765d-42ba-dee1-0afd5455ebb6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       Consumption; Consumption inequality; Credit co...\n",
              "1       Bank branch expansion; Financial permeation; F...\n",
              "2       Customer value; FinTech; Gamification; Marketi...\n",
              "3       Crowdfunding; Fintech; Health crowdfunding; He...\n",
              "4       Asymmetric information; Consumer credit; Exper...\n",
              "                              ...                        \n",
              "3395                                                  NaN\n",
              "3396                                                  NaN\n",
              "3397    Genetic-neural network; Short-term forecasting...\n",
              "3398    Discrimination analysis; Insider trading; Mark...\n",
              "3399    correlation dimension; KSE-100 index returns; ...\n",
              "Name: Author Keywords, Length: 3400, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "data['Author Keywords']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIjzOCrED2UD"
      },
      "source": [
        "### Preprocessing the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjWVXlCDD2UD"
      },
      "outputs": [],
      "source": [
        "data = data[['Authors', 'Author(s) ID','Title', 'Abstract','Year', 'Source title', 'Author Keywords']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXD6XXY9D2UE"
      },
      "outputs": [],
      "source": [
        "# data['Author Keywords'].info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x--8o2WVD2UF",
        "outputId": "c4f7fd9a-8dae-4d1c-fa8d-70f3918edc65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ],
      "source": [
        "data['Author Keywords'] = data['Author Keywords'].astype({'Author Keywords':'string'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDHNpWAjD2UF",
        "outputId": "953aae9d-70d5-43a8-b687-8f71377ff4a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       Consumption; Consumption inequality; Credit co...\n",
              "1       Bank branch expansion; Financial permeation; F...\n",
              "2       Customer value; FinTech; Gamification; Marketi...\n",
              "3       Crowdfunding; Fintech; Health crowdfunding; He...\n",
              "4       Asymmetric information; Consumer credit; Exper...\n",
              "                              ...                        \n",
              "3395                                                 <NA>\n",
              "3396                                                 <NA>\n",
              "3397    Genetic-neural network; Short-term forecasting...\n",
              "3398    Discrimination analysis; Insider trading; Mark...\n",
              "3399    correlation dimension; KSE-100 index returns; ...\n",
              "Name: Author Keywords, Length: 3400, dtype: string"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "data['Author Keywords']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnzWSAxKD2UG",
        "outputId": "83cfa5ee-d5ed-4e2d-a527-cc0e4fe13705"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  return func(*args, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "data.dropna(inplace = True,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwv-tn6OD2UH",
        "outputId": "c7fd7287-93f8-45fd-9a39-da5f8e5978f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Consumption; Consumption inequality; Credit co...\n",
              "1    Bank branch expansion; Financial permeation; F...\n",
              "2    Customer value; FinTech; Gamification; Marketi...\n",
              "3    Crowdfunding; Fintech; Health crowdfunding; He...\n",
              "4    Asymmetric information; Consumer credit; Exper...\n",
              "Name: Author Keywords, dtype: string"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "data['Author Keywords'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZW9FiCqHD2UH",
        "outputId": "69163f0b-0efe-4658-de35-7c12e9387cd6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    2781\n",
              "Name: Author Keywords, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "data['Author Keywords'].isnull().value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoV_x76oD2UI",
        "outputId": "67f67105-7742-4d55-8404-261707aef854"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/2781 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
            "  warnings.warn(Warnings.W108)\n",
            " 99%|█████████▉| 2755/2781 [00:06<00:00, 589.68it/s]"
          ]
        }
      ],
      "source": [
        "# run progress bar and clean up using spacy but without some heavy parts of the pipeline\n",
        "\n",
        "clean_text = []\n",
        "\n",
        "pbar = tqdm.tqdm(total=len(data['Author Keywords']),position=0, leave=True)\n",
        "\n",
        "for text in nlp.pipe(data['Author Keywords'], disable=[\"tagger\", \"parser\", \"ner\"]):\n",
        "\n",
        "  txt = [token.lemma_.lower() for token in text \n",
        "         if token.is_alpha \n",
        "         and not token.is_stop \n",
        "         and not token.is_punct]\n",
        "\n",
        "  clean_text.append(\" \".join(txt))\n",
        "\n",
        "  pbar.update(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtkljYgFD2UJ"
      },
      "outputs": [],
      "source": [
        "# write everything into one function that can be re-used later\n",
        "def text_prepro(texts):\n",
        "  \"\"\"\n",
        "  takes in a pandas series (1 column of a DF)\n",
        "  removes twitter stuff\n",
        "  lowercases, normalizes text\n",
        "  \"\"\"\n",
        "  texts_clean = texts.map(lambda t: prepro.clean(t))\n",
        "  clean_container = []\n",
        "\n",
        "  pbar = tqdm.tqdm(total=len(texts_clean),position=0, leave=True)\n",
        "\n",
        "  for text in nlp.pipe(texts_clean, disable=[\"tagger\", \"parser\", \"ner\"]):\n",
        "\n",
        "    txt = [token.lemma_.lower() for token in text \n",
        "          if token.is_alpha \n",
        "          and not token.is_stop \n",
        "          and not token.is_punct]\n",
        "\n",
        "    clean_container.append(\" \".join(txt))\n",
        "    pbar.update(1)\n",
        "  \n",
        "  return clean_container"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "gJk3hNMXD2UJ",
        "outputId": "e89801e3-6284-474e-9bbf-f1a6463c5b8e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-fedb8e3ebc31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# apply all prepro-pipeline to texts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Author_Keywords'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_prepro\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Author Keywords'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-24-c67ea0d6c769>\u001b[0m in \u001b[0;36mtext_prepro\u001b[0;34m(texts)\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mlowercases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalizes\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \"\"\"\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mtexts_clean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprepro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0mclean_container\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, arg, na_action)\u001b[0m\n\u001b[1;32m   4159\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4160\u001b[0m         \"\"\"\n\u001b[0;32m-> 4161\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4162\u001b[0m         return self._constructor(new_values, index=self.index).__finalize__(\n\u001b[1;32m   4163\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"map\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_map_values\u001b[0;34m(self, mapper, na_action)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0;31m# mapper is a function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-c67ea0d6c769>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mlowercases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalizes\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \"\"\"\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mtexts_clean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprepro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0mclean_container\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'preprocessor' has no attribute 'clean'"
          ]
        }
      ],
      "source": [
        "# apply all prepro-pipeline to texts\n",
        "data['Author_Keywords'] = text_prepro(data['Author Keywords'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-AavgpuD2UK"
      },
      "outputs": [],
      "source": [
        "# preprocess texts (we need tokens)\n",
        "tokens = []\n",
        "\n",
        "for summary in nlp.pipe(data['Author Keywords'], disable=[\"ner\"]):\n",
        "  proj_tok = [token.lemma_.lower() for token in summary \n",
        "              if token.pos_ in ['NOUN', 'PROPN', 'ADJ', 'ADV'] \n",
        "              and not token.is_stop\n",
        "              and not token.is_punct] \n",
        "  tokens.append(proj_tok)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8W1SJLHD2UK",
        "outputId": "103d6e32-14fe-4f21-fe0f-c6422e45d4fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ],
      "source": [
        "data['tokens'] = tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKurUUVyD2UK"
      },
      "outputs": [],
      "source": [
        "# Create a Dictionary from the articles: dictionary\n",
        "dictionary = Dictionary(data['tokens'])\n",
        "# filter out low-frequency / high-frequency stuff, also limit the vocabulary to max 500 words, since we have a low sample size ( In the example he did, he used 1000)\n",
        "dictionary.filter_extremes(no_below=50, no_above=0.5, keep_n=1000)\n",
        "# construct corpus using this dictionary\n",
        "corpus = [dictionary.doc2bow(doc) for doc in data['tokens']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCKrV34cD2UL"
      },
      "source": [
        "### UML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OKlgESCD2UM"
      },
      "outputs": [],
      "source": [
        "#Importing UML packages\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ovV4NSyPD2UM"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWzy_-KsD2UM"
      },
      "outputs": [],
      "source": [
        "sparse_matrix =tfidf.fit_transform(data['Author Keywords'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnjUBuuJD2UM"
      },
      "outputs": [],
      "source": [
        "#Import nmf\n",
        "from sklearn.decomposition import NMF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqpaks72D2UN"
      },
      "outputs": [],
      "source": [
        "#Using 4 components in order to determine relevancy\n",
        "nmf = NMF(n_components=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hAIGSzXD2UN",
        "outputId": "cc9f9c93-2c9d-445d-8bb9-d782d2d3a67f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_nmf.py:294: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "matrix_nmf = nmf.fit_transform(sparse_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_rB4t9aD2UO",
        "outputId": "7a8fabc0-9d4a-48e4-8d71-5a296cfa41e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2781, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "matrix_nmf.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOjxxkydD2UP",
        "outputId": "734859f0-5b23-46f1-8d9f-c7ae69ff3244"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2781,)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "data['Author Keywords'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgVcAgrED2UP",
        "outputId": "c62b9841-4436-4150-ab42-e14e140d1514"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 3841)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "nmf.components_.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXFa2t9UD2UR"
      },
      "outputs": [],
      "source": [
        "matrix_nmf = matrix_nmf.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCdYh81jD2UR",
        "outputId": "918c470b-ac33-452b-871b-6fac73d33bad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 2781)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "matrix_nmf.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lda_model = LdaMulticore(corpus, id2word=dictionary, num_topics=5, workers = 4, passes=10)"
      ],
      "metadata": {
        "id": "shTN07uFFg45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic_dist = lda_model[corpus]"
      ],
      "metadata": {
        "id": "gkCi9sLdFdDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wap_XVxXD2US",
        "outputId": "8cb35df6-a298-4a5e-e23f-8cdaf9405abb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n"
          ]
        }
      ],
      "source": [
        "dist = []\n",
        "\n",
        "for t in topic_dist:\n",
        "    dist.append(t)  \n",
        "    \n",
        "# add list to the data frame\n",
        "data['Topic Distribution'] = dist\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['Topic Distribution']"
      ],
      "metadata": {
        "id": "oF0ONkpJFpYi",
        "outputId": "28727dac-890b-4a6a-eae0-012705d5679a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       [(0, 0.05008506), (1, 0.7984384), (2, 0.050986...\n",
              "1       [(0, 0.06700229), (1, 0.06699108), (2, 0.43726...\n",
              "2       [(0, 0.028613161), (1, 0.88472974), (2, 0.0285...\n",
              "3       [(0, 0.06747732), (1, 0.067560114), (2, 0.0670...\n",
              "4       [(0, 0.050192535), (1, 0.42654723), (2, 0.0513...\n",
              "                              ...                        \n",
              "3391    [(0, 0.10000247), (1, 0.10000088), (2, 0.10002...\n",
              "3393    [(0, 0.04024373), (1, 0.04054168), (2, 0.21572...\n",
              "3397    [(0, 0.0400007), (1, 0.040003985), (2, 0.04001...\n",
              "3398    [(0, 0.033655155), (1, 0.033496186), (2, 0.033...\n",
              "3399    [(0, 0.050023414), (1, 0.050393008), (2, 0.050...\n",
              "Name: Topic Distribution, Length: 2781, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9FkklowD2UT"
      },
      "outputs": [],
      "source": [
        "\n",
        "list_topicnum = []\n",
        "for itm in range(len(data)):\n",
        "    list_topicnum.append(sorted(data['Topic Distribution'][itm], key=lambda tup: tup[1], reverse=True)[0][0])\n",
        "data['topic_num'] = list_topicnum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DhD_DV1D2UT"
      },
      "outputs": [],
      "source": [
        "#2 components are more relevant\n",
        "plt.figure(figsize=(20,3))\n",
        "sns.heatmap(pd.DataFrame(nmf.components_, columns=data['Author Keywords']), annot=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqN9uHQXD2UU"
      },
      "source": [
        "#### K-means and clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCkR3nS0D2UU"
      },
      "outputs": [],
      "source": [
        "import umap.umap_ as umap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oE5TvPg6D2UV"
      },
      "outputs": [],
      "source": [
        "umap_scaler = umap.UMAP()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0DHeq_eD2UV"
      },
      "outputs": [],
      "source": [
        "#Using standard scaling data\n",
        "embeddings = umap_scaler.fit_transform(matrix_nmf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSXUjHYrD2UW"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "clusterer = KMeans(n_clusters=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZA44QnYrD2UW"
      },
      "outputs": [],
      "source": [
        "Sum_of_squared_distances = []\n",
        "K = range(1,10)\n",
        "for k in K:\n",
        "    km = KMeans(n_clusters=k)\n",
        "    km = km.fit(embeddings)\n",
        "    Sum_of_squared_distances.append(km.inertia_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSkoMYHoD2UW"
      },
      "source": [
        "##### Elbow Method for clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PnW11P4RD2UX"
      },
      "outputs": [],
      "source": [
        "plt.plot(K, Sum_of_squared_distances, 'bx-')\n",
        "plt.xlabel('k')\n",
        "plt.ylabel('Sum_of_squared_distances')\n",
        "plt.title('Elbow Method For Optimal k')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6HQFrMsvD2UX"
      },
      "outputs": [],
      "source": [
        "umap_scaler_km = umap.UMAP(n_components=6)\n",
        "embeddings_km = umap_scaler.fit_transform(matrix_nmf)\n",
        "\n",
        "\n",
        "Sum_of_squared_distances = []\n",
        "K = range(1,10)\n",
        "for k in K:\n",
        "    km = KMeans(n_clusters=k)\n",
        "    km = km.fit(embeddings_km)\n",
        "    Sum_of_squared_distances.append(km.inertia_)\n",
        "\n",
        "\n",
        "plt.plot(K, Sum_of_squared_distances, 'bx-')\n",
        "plt.xlabel('k')\n",
        "plt.ylabel('Sum_of_squared_distances')\n",
        "plt.title('Elbow Method For Optimal k')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27xPwPxcD2UX"
      },
      "outputs": [],
      "source": [
        "#Assign variables some values\n",
        "clusterer = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
        "label = clusterer.fit_predict(embeddings)\n",
        "centroids = clusterer.cluster_centers_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXBfLNF2D2UY"
      },
      "outputs": [],
      "source": [
        "#Creating data for clustering using an interactive map\n",
        "vis_data = pd.DataFrame(embeddings)\n",
        "\n",
        "# vis_data.columns = ['x', 'y', 'EmployeeID', 'Department']\n",
        "\n",
        "alt.Chart(vis_data).mark_circle(size=60).encode(\n",
        "    x='x',\n",
        "    y='y',\n",
        "    # tooltip=['']\n",
        ").interactive()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjF4nFIFD2UZ"
      },
      "outputs": [],
      "source": [
        "#Assigning groups to the clusters\n",
        "\n",
        "print(label)\n",
        "df_t = pd.DataFrame(data=embeddings, columns=['x', 'y'])\n",
        "df_t['EmployeeID'] = data_hr['EmployeeID']\n",
        "df_t['Department'] = data_hr['Department']\n",
        "df_t.columns = ['x', 'y', 'EmployeeID', 'Department']\n",
        "df_t['label'] = label\n",
        "only_0 = df_t[df_t['label'] == 0]\n",
        "only_1 = df_t[df_t['label'] == 1]\n",
        "only_2 = df_t[df_t['label'] == 2]\n",
        "\n",
        "plt.scatter(only_0['x'], only_0['y'], color='blue')\n",
        "plt.scatter(only_1['x'], only_1['y'], color='red')\n",
        "plt.scatter(only_2['x'],only_2['y'], color ='green')\n",
        "df_t.info()\n",
        "df_t.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IoaVr35D2UZ"
      },
      "outputs": [],
      "source": [
        "# We have to scale and transform our data into numerical values since they are categorical values \n",
        "le_keywords = LabelEncoder()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWFqlyngD2Ua"
      },
      "outputs": [],
      "source": [
        "data['keywords_ID'] = le_keywords.fit_transform(data['Author Keywords'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2tlw5FDD2Ua"
      },
      "outputs": [],
      "source": [
        "data['Title_ID'] = le_keywords.fit_transform(data['Title'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3OEJcrZD2Ua"
      },
      "outputs": [],
      "source": [
        "ones = np.ones(len(data), np.uint32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jssjKkWsD2Ua"
      },
      "outputs": [],
      "source": [
        "data['keywords_ID']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49IShklUD2Ub"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QygrCKevD2Ub"
      },
      "outputs": [],
      "source": [
        "#Importing UML packages\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIKFlGR1D2Ub"
      },
      "outputs": [],
      "source": [
        "#Learn x-y relationships (principal components) and transform\n",
        "data_to_cluster_scaled = scaler.fit_transform(data['keywords_ID'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xChA4msWD2Ub"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXMfIo5kD2Ub"
      },
      "outputs": [],
      "source": [
        "data.Author_Keywords.value_counts().reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3B-ww7KD2Uc"
      },
      "outputs": [],
      "source": [
        "data.text_clean.value_counts().reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2EFKJ5KD2Uc"
      },
      "outputs": [],
      "source": [
        "data['text_clean'].info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ioROTVvD2Uc"
      },
      "outputs": [],
      "source": [
        "data['Categories'].info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDet_IXID2Uc"
      },
      "source": [
        "#### Fixing the imbalances and transforming the data into numerical values "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzL2SVUND2Uc"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJ67g1vrD2Uc"
      },
      "outputs": [],
      "source": [
        "le_keywords = LabelEncoder()\n",
        "le_text_clean = LabelEncoder()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsMUaSbTD2Ud"
      },
      "outputs": [],
      "source": [
        "data['Keyword_ID'] = le_keywords.fit_transform(data['Author Keywords'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EuMRL3RDD2Ud"
      },
      "outputs": [],
      "source": [
        "data['text_clean_ID'] = le_text_clean.fit_transform(data['text_clean'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IEDVK6yD2Ud"
      },
      "outputs": [],
      "source": [
        "data.Categories_ID.value_counts().reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQhYPCZkD2Ud"
      },
      "outputs": [],
      "source": [
        "data.text_clean_ID.value_counts().reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyR5JcbCD2Ud"
      },
      "outputs": [],
      "source": [
        "data[data['Categories_ID'] == 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJTpy-41D2Ue"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "from numpy.random import RandomState\n",
        "from sklearn.datasets import make_classification\n",
        "from imblearn.over_sampling import SMOTENC\n",
        "SM = sm = SMOTENC(random_state=42, categorical_features=[18, 19])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jN7hWCXmD2Ue"
      },
      "outputs": [],
      "source": [
        "data['text_clean_ID']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MD4m1ZNcD2Ue"
      },
      "outputs": [],
      "source": [
        "data['Categories_ID']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOHDVCd0D2Ue"
      },
      "outputs": [],
      "source": [
        "# Here we use oversampling, since the distribution of the y value is skewed \n",
        "X_train_SMOTEN, y_train_SMOTEN = sm.fit_resample(data['text_clean'], data['Categories'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8C8S-54RD2Ue"
      },
      "outputs": [],
      "source": [
        "# Splitting the dataset into the Training set and Test set (since we have a new output variable)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['text_clean'], data['Categories'], test_size = 0.2, random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oK9aGXmVD2Uf"
      },
      "outputs": [],
      "source": [
        "#instantiate models and \"bundle up as pipeline\"\n",
        "\n",
        "tfidf = TfidfVectorizer()\n",
        "cls = LogisticRegression()\n",
        "\n",
        "pipe = make_pipeline(tfidf, cls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAykPYH7D2Uf"
      },
      "outputs": [],
      "source": [
        "pipe.fit(X_train,y_train) # fit model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CeeJtD-wD2Uf"
      },
      "outputs": [],
      "source": [
        "# evaluate model performance on training set\n",
        "\n",
        "y_eval = pipe.predict(X_train)\n",
        "report = classification_report(y_train, y_eval)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2DVUJrfD2Uf"
      },
      "outputs": [],
      "source": [
        "# evaluate model performance on test set\n",
        "\n",
        "y_pred = pipe.predict(X_test)\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwF9Rx_fD2Uf"
      },
      "outputs": [],
      "source": [
        "t1 = ['']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8Hd5FPoD2Ug"
      },
      "outputs": [],
      "source": [
        "t1_p = text_prepro(pd.Series(t1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_iLnbvgmD2Ug"
      },
      "outputs": [],
      "source": [
        "pipe.predict (t1_p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fh9bpNgKD2Ug"
      },
      "source": [
        "### Topic modelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VerMa5kzD2Ug"
      },
      "outputs": [],
      "source": [
        "lda_model = LdaMulticore(corpus, id2word=dictionary, num_topics=5, workers = 4, passes=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dl9h9tPAD2Ug"
      },
      "outputs": [],
      "source": [
        "# Let's try to visualize\n",
        "lda_display = pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IM6AZii_D2Ug"
      },
      "outputs": [],
      "source": [
        " # Let's Visualize\n",
        "pyLDAvis.display(lda_display)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgHWMeFoD2Uh"
      },
      "source": [
        "### We will use a coherence matrix to find out how many topics we need for topic modelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l34LZpTID2Uh"
      },
      "outputs": [],
      "source": [
        "# cm = CoherenceModel(model=lda_model, corpus=corpus, coherence='u_mass')\n",
        "# coherence = cm.get_coherence()  # get coherence value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9iUkppxD2Uh"
      },
      "outputs": [],
      "source": [
        "data = data.reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNBItmApD2Uh"
      },
      "outputs": [],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Z2zstzJD2Uh"
      },
      "outputs": [],
      "source": [
        "data = data[data[\"tokens\"].str.len() != 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzhUASizD2Ui"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tl5FsA6qD2Ui"
      },
      "outputs": [],
      "source": [
        "corpus = data['tokens']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3pLzEvkD2Ui"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3EIg_0OCD2Ui"
      },
      "outputs": [],
      "source": [
        "data.tokens.value_counts().reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4KIGKqGD2Ui"
      },
      "outputs": [],
      "source": [
        "dirichlet_dict = corpora.Dictionary(corpus)\n",
        "bow_corpus = [dirichlet_dict.doc2bow(text) for text in corpus]\n",
        "\n",
        "# Considering 1-15 topics, as the last is cut off\n",
        "num_topics = list(range(10)[1:])\n",
        "num_keywords = 15\n",
        "\n",
        "LDA_models = {}\n",
        "LDA_topics = {}\n",
        "for i in num_topics:\n",
        "    LDA_models[i] = LdaModel(corpus=bow_corpus,\n",
        "                             id2word=dirichlet_dict,\n",
        "                             num_topics=i,\n",
        "                             update_every=1,\n",
        "                             chunksize=len(bow_corpus),\n",
        "                             passes=10,\n",
        "                             alpha='auto',\n",
        "                             random_state=42)\n",
        "\n",
        "    shown_topics = LDA_models[i].show_topics(num_topics=i, \n",
        "                                             num_words=num_keywords,\n",
        "                                             formatted=False)\n",
        "    LDA_topics[i] = [[word[0] for word in topic[1]] for topic in shown_topics]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmTZo_WHD2Uj"
      },
      "outputs": [],
      "source": [
        "def jaccard_similarity(topic_1, topic_2):\n",
        "    \"\"\"\n",
        "    Derives the Jaccard similarity of two topics\n",
        "\n",
        "    Jaccard similarity:\n",
        "    - A statistic used for comparing the similarity and diversity of sample sets\n",
        "    - J(A,B) = (A ∩ B)/(A ∪ B)\n",
        "    - Goal is low Jaccard scores for coverage of the diverse elements\n",
        "    \"\"\"\n",
        "    intersection = set(topic_1).intersection(set(topic_2))\n",
        "    union = set(topic_1).union(set(topic_2))\n",
        "                    \n",
        "    return float(len(intersection))/float(len(union))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvJ5jSseD2Uj"
      },
      "outputs": [],
      "source": [
        "LDA_stability = {}\n",
        "for i in range(0, len(num_topics)-1):\n",
        "    jaccard_sims = []\n",
        "    for t1, topic1 in enumerate(LDA_topics[num_topics[i]]): # pylint: disable=unused-variable\n",
        "        sims = []\n",
        "        for t2, topic2 in enumerate(LDA_topics[num_topics[i+1]]): # pylint: disable=unused-variable\n",
        "            sims.append(jaccard_similarity(topic1, topic2))    \n",
        "        \n",
        "        jaccard_sims.append(sims)    \n",
        "    \n",
        "    LDA_stability[num_topics[i]] = jaccard_sims\n",
        "                \n",
        "mean_stabilities = [np.array(LDA_stability[i]).mean() for i in num_topics[:-1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EooFV5v9D2Uk"
      },
      "outputs": [],
      "source": [
        "coherences = [CoherenceModel(model=LDA_models[i], texts=corpus, dictionary=dirichlet_dict, coherence='c_v').get_coherence() for i in num_topics[:-1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0RlkvOHD2Uk"
      },
      "outputs": [],
      "source": [
        "num_keywords = len(coherences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cwFsMrGD2Uk"
      },
      "outputs": [],
      "source": [
        "coh_sta_diffs = [coherences[i] - mean_stabilities[i] for i in range(num_keywords)[:-1]] # limit topic numbers to the number of keywords\n",
        "coh_sta_max = max(coh_sta_diffs)\n",
        "coh_sta_max_idxs = [i for i, j in enumerate(coh_sta_diffs) if j == coh_sta_max]\n",
        "ideal_topic_num_index = coh_sta_max_idxs[0] # choose less topics in case there's more than one max\n",
        "ideal_topic_num = num_topics[ideal_topic_num_index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lHmkEi-D2Uk"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "ax = sns.lineplot(x=num_topics[:-1], y=mean_stabilities, label='Average Topic Overlap')\n",
        "ax = sns.lineplot(x=num_topics[:-1], y=coherences, label='Topic Coherence')\n",
        "\n",
        "ax.axvline(x=ideal_topic_num, label='Ideal Number of Topics', color='black')\n",
        "ax.axvspan(xmin=ideal_topic_num - 1, xmax=ideal_topic_num + 1, alpha=0.5, facecolor='grey')\n",
        "\n",
        "y_max = max(max(mean_stabilities), max(coherences)) + (0.10 * max(max(mean_stabilities), max(coherences)))\n",
        "ax.set_ylim([0, y_max])\n",
        "ax.set_xlim([1, num_topics[-1]-1])\n",
        "                \n",
        "ax.axes.set_title('Model Metrics per Number of Topics', fontsize=25)\n",
        "ax.set_ylabel('Metric Level', fontsize=20)\n",
        "ax.set_xlabel('Number of Topics', fontsize=20)\n",
        "plt.legend(fontsize=20)\n",
        "plt.show()  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZm1bY71D2Ul"
      },
      "outputs": [],
      "source": [
        "t, s = get_lda_topics(lda_model_sample, corpus_sample)\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "data[\"keyword_label\"] = t\n",
        "\n",
        "data[\"keyword_label_score\"] = s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlLbU00iD2Ul"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "995406004189bc7a762cd15e0adc766b4032076a3e0cf164ca390850079b6fa1"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}