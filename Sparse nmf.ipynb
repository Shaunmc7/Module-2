{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All the packages that will be needed for natural language processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from spacy.lang.en import English\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import preprocessor as prepro # text prepro\n",
    "import tqdm #progress bar\n",
    "from gensim.models import LdaModel, CoherenceModel\n",
    "from gensim import corpora\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "SMOTE = SMOTE()\n",
    "import spacy #spacy for quick language prepro\n",
    "nlp = spacy.load('en_core_web_sm') #instantiating English module\n",
    "import scipy.sparse as ss\n",
    "\n",
    "# sampling, splitting\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# loading ML libraries\n",
    "from sklearn.pipeline import make_pipeline #pipeline creation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer #transforms text to sparse matrix\n",
    "from sklearn.linear_model import LogisticRegression #Logit model\n",
    "from sklearn.metrics import classification_report #that's self explanatory\n",
    "from sklearn.decomposition import TruncatedSVD #dimensionality reduction\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import altair as alt #viz\n",
    "\n",
    "#explainability\n",
    "import eli5\n",
    "from eli5.lime import TextExplainer\n",
    "\n",
    "# topic modeling\n",
    "\n",
    "from gensim.corpora.dictionary import Dictionary # Import the dictionary builder\n",
    "from gensim.models import LdaMulticore # we'll use the faster multicore version of LDA\n",
    "\n",
    "# Import pyLDAvis\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "\n",
    "%matplotlib inline\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepro settings\n",
    "# This is prob not relevant, since it has to do with tweets? \n",
    "# prepro.set_options(prepro.OPT.URL, prepro.OPT.NUMBER, prepro.OPT.RESERVED, prepro.OPT.MENTION, prepro.OPT.SMILEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and appending the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scopus2022 = pd.read_csv('scopus 2022 2021.csv',  sep = ',')\n",
    "scopus = pd.read_csv('scopus.csv',  sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maart\\AppData\\Local\\Temp\\ipykernel_19344\\3402760882.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = scopus2022.append(scopus, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "data = scopus2022.append(scopus, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Authors</th>\n",
       "      <th>Author(s) ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Source title</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Art. No.</th>\n",
       "      <th>Page start</th>\n",
       "      <th>Page end</th>\n",
       "      <th>...</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>CODEN</th>\n",
       "      <th>PubMed ID</th>\n",
       "      <th>Language of Original Document</th>\n",
       "      <th>Abbreviated Source Title</th>\n",
       "      <th>Document Type</th>\n",
       "      <th>Publication Stage</th>\n",
       "      <th>Open Access</th>\n",
       "      <th>Source</th>\n",
       "      <th>EID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yang T., Zhang X.</td>\n",
       "      <td>57907798100;56342888200;</td>\n",
       "      <td>FinTech adoption and financial inclusion: Evid...</td>\n",
       "      <td>2022</td>\n",
       "      <td>Journal of Banking and Finance</td>\n",
       "      <td>145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106668</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JBFID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>J. Bank. Financ.</td>\n",
       "      <td>Article</td>\n",
       "      <td>Final</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>2-s2.0-85138806241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wang X., Wang Y., Zhao Y.</td>\n",
       "      <td>57193015825;57901727900;57901783600;</td>\n",
       "      <td>Financial permeation and rural poverty reducti...</td>\n",
       "      <td>2022</td>\n",
       "      <td>China Economic Review</td>\n",
       "      <td>76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101863</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>China Econ. Rev.</td>\n",
       "      <td>Article</td>\n",
       "      <td>Final</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>2-s2.0-85138589769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dzandu M.D., Hanu C., Amegbe H.</td>\n",
       "      <td>56590001600;57201152816;57194904537;</td>\n",
       "      <td>Gamification of mobile money payment for gener...</td>\n",
       "      <td>2022</td>\n",
       "      <td>Technological Forecasting and Social Change</td>\n",
       "      <td>185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122049</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Technol. Forecast. Soc. Change</td>\n",
       "      <td>Article</td>\n",
       "      <td>Final</td>\n",
       "      <td>All Open Access, Hybrid Gold, Green</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>2-s2.0-85138450268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Grassi L., Fantaccini S.</td>\n",
       "      <td>57192656409;57895835500;</td>\n",
       "      <td>An overview of Fintech applications to solve t...</td>\n",
       "      <td>2022</td>\n",
       "      <td>Financial Innovation</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Financial Innov.</td>\n",
       "      <td>Article</td>\n",
       "      <td>Final</td>\n",
       "      <td>All Open Access, Gold, Green</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>2-s2.0-85138286241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DeFusco A.A., Tang H., Yannelis C.</td>\n",
       "      <td>57193852071;57890330600;55413678100;</td>\n",
       "      <td>Measuring the welfare cost of asymmetric infor...</td>\n",
       "      <td>2022</td>\n",
       "      <td>Journal of Financial Economics</td>\n",
       "      <td>146</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>821</td>\n",
       "      <td>840.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JFECD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>J. Financ. Econ.</td>\n",
       "      <td>Article</td>\n",
       "      <td>Final</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>2-s2.0-85138101180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3395</th>\n",
       "      <td>Fayard E.H.</td>\n",
       "      <td>35072693600;</td>\n",
       "      <td>ACC pressure cleaning</td>\n",
       "      <td>2010</td>\n",
       "      <td>Power Engineering (Barrington, Illinois)</td>\n",
       "      <td>114</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POENA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Power Eng. Barrington Ill</td>\n",
       "      <td>Short Survey</td>\n",
       "      <td>Final</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>2-s2.0-77953829082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3396</th>\n",
       "      <td>Dassanayake M.M.K., Tilakarathne C.</td>\n",
       "      <td>57221353725;55762978100;</td>\n",
       "      <td>Predicting trading signals of Sri Lankan stock...</td>\n",
       "      <td>2010</td>\n",
       "      <td>Technological Developments in Networking, Educ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>269</td>\n",
       "      <td>273</td>\n",
       "      <td>...</td>\n",
       "      <td>9789048191505</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Technol. Dev. Networking, Educ. Autom.</td>\n",
       "      <td>Conference Paper</td>\n",
       "      <td>Final</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>2-s2.0-84878897261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3397</th>\n",
       "      <td>Hao H.-N.</td>\n",
       "      <td>36617357100;</td>\n",
       "      <td>Notice of Retraction: Short-term forecasting o...</td>\n",
       "      <td>2010</td>\n",
       "      <td>Proceedings - 2010 6th International Conferenc...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5584528</td>\n",
       "      <td>1838</td>\n",
       "      <td>1841</td>\n",
       "      <td>...</td>\n",
       "      <td>9781424459612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Proc. - Int. Conf. Nat. Comput., ICNC</td>\n",
       "      <td>Retracted</td>\n",
       "      <td>Final</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>2-s2.0-78149350510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3398</th>\n",
       "      <td>Ma Z.-X., Zhang W.</td>\n",
       "      <td>55479146300;56621528900;</td>\n",
       "      <td>Notice of Retraction: An discrimination resear...</td>\n",
       "      <td>2010</td>\n",
       "      <td>ICAMS 2010 - Proceedings of 2010 IEEE Internat...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5553273</td>\n",
       "      <td>116</td>\n",
       "      <td>119</td>\n",
       "      <td>...</td>\n",
       "      <td>9781424469291</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>ICAMS - Proc. IEEE Int. Conf. Adv. Manage. Sci.</td>\n",
       "      <td>Retracted</td>\n",
       "      <td>Final</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>2-s2.0-77957273781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3399</th>\n",
       "      <td>Danial S.N., Noor S.R., Usmani B.A., Zaidi S.J.H.</td>\n",
       "      <td>24823887800;24825002200;26666352700;57549810600;</td>\n",
       "      <td>A dynamical system and neural network perspect...</td>\n",
       "      <td>2008</td>\n",
       "      <td>Communications in Computer and Information Sci...</td>\n",
       "      <td>20 CCIS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>3540898522; 9783540898528</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Commun. Comput. Info. Sci.</td>\n",
       "      <td>Conference Paper</td>\n",
       "      <td>Final</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>2-s2.0-85099426338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3400 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Authors  \\\n",
       "0                                     Yang T., Zhang X.   \n",
       "1                             Wang X., Wang Y., Zhao Y.   \n",
       "2                       Dzandu M.D., Hanu C., Amegbe H.   \n",
       "3                              Grassi L., Fantaccini S.   \n",
       "4                    DeFusco A.A., Tang H., Yannelis C.   \n",
       "...                                                 ...   \n",
       "3395                                        Fayard E.H.   \n",
       "3396                Dassanayake M.M.K., Tilakarathne C.   \n",
       "3397                                          Hao H.-N.   \n",
       "3398                                 Ma Z.-X., Zhang W.   \n",
       "3399  Danial S.N., Noor S.R., Usmani B.A., Zaidi S.J.H.   \n",
       "\n",
       "                                          Author(s) ID  \\\n",
       "0                             57907798100;56342888200;   \n",
       "1                 57193015825;57901727900;57901783600;   \n",
       "2                 56590001600;57201152816;57194904537;   \n",
       "3                             57192656409;57895835500;   \n",
       "4                 57193852071;57890330600;55413678100;   \n",
       "...                                                ...   \n",
       "3395                                      35072693600;   \n",
       "3396                          57221353725;55762978100;   \n",
       "3397                                      36617357100;   \n",
       "3398                          55479146300;56621528900;   \n",
       "3399  24823887800;24825002200;26666352700;57549810600;   \n",
       "\n",
       "                                                  Title  Year  \\\n",
       "0     FinTech adoption and financial inclusion: Evid...  2022   \n",
       "1     Financial permeation and rural poverty reducti...  2022   \n",
       "2     Gamification of mobile money payment for gener...  2022   \n",
       "3     An overview of Fintech applications to solve t...  2022   \n",
       "4     Measuring the welfare cost of asymmetric infor...  2022   \n",
       "...                                                 ...   ...   \n",
       "3395                              ACC pressure cleaning  2010   \n",
       "3396  Predicting trading signals of Sri Lankan stock...  2010   \n",
       "3397  Notice of Retraction: Short-term forecasting o...  2010   \n",
       "3398  Notice of Retraction: An discrimination resear...  2010   \n",
       "3399  A dynamical system and neural network perspect...  2008   \n",
       "\n",
       "                                           Source title   Volume Issue  \\\n",
       "0                        Journal of Banking and Finance      145   NaN   \n",
       "1                                 China Economic Review       76   NaN   \n",
       "2           Technological Forecasting and Social Change      185   NaN   \n",
       "3                                  Financial Innovation        8     1   \n",
       "4                        Journal of Financial Economics      146     3   \n",
       "...                                                 ...      ...   ...   \n",
       "3395           Power Engineering (Barrington, Illinois)      114     5   \n",
       "3396  Technological Developments in Networking, Educ...      NaN   NaN   \n",
       "3397  Proceedings - 2010 6th International Conferenc...        4   NaN   \n",
       "3398  ICAMS 2010 - Proceedings of 2010 IEEE Internat...        3   NaN   \n",
       "3399  Communications in Computer and Information Sci...  20 CCIS   NaN   \n",
       "\n",
       "     Art. No. Page start Page end  ...                       ISBN  CODEN  \\\n",
       "0      106668        NaN      NaN  ...                        NaN  JBFID   \n",
       "1      101863        NaN      NaN  ...                        NaN    NaN   \n",
       "2      122049        NaN      NaN  ...                        NaN    NaN   \n",
       "3          84        NaN      NaN  ...                        NaN    NaN   \n",
       "4         NaN        821    840.0  ...                        NaN  JFECD   \n",
       "...       ...        ...      ...  ...                        ...    ...   \n",
       "3395      NaN         22      NaN  ...                        NaN  POENA   \n",
       "3396      NaN        269      273  ...              9789048191505    NaN   \n",
       "3397  5584528       1838     1841  ...              9781424459612    NaN   \n",
       "3398  5553273        116      119  ...              9781424469291    NaN   \n",
       "3399      NaN         88       99  ...  3540898522; 9783540898528    NaN   \n",
       "\n",
       "     PubMed ID Language of Original Document  \\\n",
       "0          NaN                       English   \n",
       "1          NaN                       English   \n",
       "2          NaN                       English   \n",
       "3          NaN                       English   \n",
       "4          NaN                       English   \n",
       "...        ...                           ...   \n",
       "3395       NaN                       English   \n",
       "3396       NaN                       English   \n",
       "3397       NaN                       English   \n",
       "3398       NaN                       English   \n",
       "3399       NaN                       English   \n",
       "\n",
       "                             Abbreviated Source Title     Document Type  \\\n",
       "0                                    J. Bank. Financ.           Article   \n",
       "1                                    China Econ. Rev.           Article   \n",
       "2                      Technol. Forecast. Soc. Change           Article   \n",
       "3                                    Financial Innov.           Article   \n",
       "4                                    J. Financ. Econ.           Article   \n",
       "...                                               ...               ...   \n",
       "3395                        Power Eng. Barrington Ill      Short Survey   \n",
       "3396           Technol. Dev. Networking, Educ. Autom.  Conference Paper   \n",
       "3397            Proc. - Int. Conf. Nat. Comput., ICNC         Retracted   \n",
       "3398  ICAMS - Proc. IEEE Int. Conf. Adv. Manage. Sci.         Retracted   \n",
       "3399                       Commun. Comput. Info. Sci.  Conference Paper   \n",
       "\n",
       "     Publication Stage                          Open Access  Source  \\\n",
       "0                Final                                  NaN  Scopus   \n",
       "1                Final                                  NaN  Scopus   \n",
       "2                Final  All Open Access, Hybrid Gold, Green  Scopus   \n",
       "3                Final         All Open Access, Gold, Green  Scopus   \n",
       "4                Final                                  NaN  Scopus   \n",
       "...                ...                                  ...     ...   \n",
       "3395             Final                                  NaN  Scopus   \n",
       "3396             Final                                  NaN  Scopus   \n",
       "3397             Final                                  NaN  Scopus   \n",
       "3398             Final                                  NaN  Scopus   \n",
       "3399             Final                                  NaN  Scopus   \n",
       "\n",
       "                     EID  \n",
       "0     2-s2.0-85138806241  \n",
       "1     2-s2.0-85138589769  \n",
       "2     2-s2.0-85138450268  \n",
       "3     2-s2.0-85138286241  \n",
       "4     2-s2.0-85138101180  \n",
       "...                  ...  \n",
       "3395  2-s2.0-77953829082  \n",
       "3396  2-s2.0-84878897261  \n",
       "3397  2-s2.0-78149350510  \n",
       "3398  2-s2.0-77957273781  \n",
       "3399  2-s2.0-85099426338  \n",
       "\n",
       "[3400 rows x 54 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3400 entries, 0 to 3399\n",
      "Data columns (total 54 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   Authors                        3400 non-null   object \n",
      " 1   Author(s) ID                   3399 non-null   object \n",
      " 2   Title                          3400 non-null   object \n",
      " 3   Year                           3400 non-null   int64  \n",
      " 4   Source title                   3400 non-null   object \n",
      " 5   Volume                         2320 non-null   object \n",
      " 6   Issue                          1426 non-null   object \n",
      " 7   Art. No.                       1051 non-null   object \n",
      " 8   Page start                     2336 non-null   object \n",
      " 9   Page end                       2326 non-null   object \n",
      " 10  Page count                     38 non-null     float64\n",
      " 11  Cited by                       2164 non-null   float64\n",
      " 12  DOI                            2972 non-null   object \n",
      " 13  Link                           3400 non-null   object \n",
      " 14  Affiliations                   3305 non-null   object \n",
      " 15  Authors with affiliations      3342 non-null   object \n",
      " 16  Abstract                       3400 non-null   object \n",
      " 17  Author Keywords                2781 non-null   object \n",
      " 18  Index Keywords                 1616 non-null   object \n",
      " 19  Molecular Sequence Numbers     0 non-null      float64\n",
      " 20  Chemicals/CAS                  4 non-null      object \n",
      " 21  Tradenames                     0 non-null      float64\n",
      " 22  Manufacturers                  0 non-null      float64\n",
      " 23  Funding Details                827 non-null    object \n",
      " 24  Funding Text 1                 1039 non-null   object \n",
      " 25  Funding Text 2                 141 non-null    object \n",
      " 26  Funding Text 3                 7 non-null      object \n",
      " 27  Funding Text 4                 1 non-null      object \n",
      " 28  Funding Text 5                 1 non-null      object \n",
      " 29  Funding Text 6                 1 non-null      object \n",
      " 30  Funding Text 7                 1 non-null      object \n",
      " 31  Funding Text 8                 0 non-null      float64\n",
      " 32  Funding Text 9                 0 non-null      float64\n",
      " 33  Funding Text 10                0 non-null      float64\n",
      " 34  References                     3212 non-null   object \n",
      " 35  Correspondence Address         2354 non-null   object \n",
      " 36  Editors                        491 non-null    object \n",
      " 37  Sponsors                       319 non-null    object \n",
      " 38  Publisher                      3394 non-null   object \n",
      " 39  Conference name                1063 non-null   object \n",
      " 40  Conference date                1062 non-null   object \n",
      " 41  Conference location            3 non-null      object \n",
      " 42  Conference code                1065 non-null   float64\n",
      " 43  ISSN                           2540 non-null   object \n",
      " 44  ISBN                           1174 non-null   object \n",
      " 45  CODEN                          276 non-null    object \n",
      " 46  PubMed ID                      36 non-null     float64\n",
      " 47  Language of Original Document  3400 non-null   object \n",
      " 48  Abbreviated Source Title       3396 non-null   object \n",
      " 49  Document Type                  3400 non-null   object \n",
      " 50  Publication Stage              3400 non-null   object \n",
      " 51  Open Access                    1097 non-null   object \n",
      " 52  Source                         3400 non-null   object \n",
      " 53  EID                            3400 non-null   object \n",
      "dtypes: float64(10), int64(1), object(43)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Authors</th>\n",
       "      <th>Author(s) ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Source title</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Art. No.</th>\n",
       "      <th>Page start</th>\n",
       "      <th>Page end</th>\n",
       "      <th>DOI</th>\n",
       "      <th>...</th>\n",
       "      <th>ISSN</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>CODEN</th>\n",
       "      <th>Language of Original Document</th>\n",
       "      <th>Abbreviated Source Title</th>\n",
       "      <th>Document Type</th>\n",
       "      <th>Publication Stage</th>\n",
       "      <th>Open Access</th>\n",
       "      <th>Source</th>\n",
       "      <th>EID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3400</td>\n",
       "      <td>3399</td>\n",
       "      <td>3400</td>\n",
       "      <td>3400</td>\n",
       "      <td>2320</td>\n",
       "      <td>1426</td>\n",
       "      <td>1051</td>\n",
       "      <td>2336</td>\n",
       "      <td>2326</td>\n",
       "      <td>2972</td>\n",
       "      <td>...</td>\n",
       "      <td>2540</td>\n",
       "      <td>1174</td>\n",
       "      <td>276</td>\n",
       "      <td>3400</td>\n",
       "      <td>3396</td>\n",
       "      <td>3400</td>\n",
       "      <td>3400</td>\n",
       "      <td>1097</td>\n",
       "      <td>3400</td>\n",
       "      <td>3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3167</td>\n",
       "      <td>3156</td>\n",
       "      <td>3389</td>\n",
       "      <td>1455</td>\n",
       "      <td>495</td>\n",
       "      <td>81</td>\n",
       "      <td>1023</td>\n",
       "      <td>1013</td>\n",
       "      <td>1369</td>\n",
       "      <td>2969</td>\n",
       "      <td>...</td>\n",
       "      <td>949</td>\n",
       "      <td>821</td>\n",
       "      <td>124</td>\n",
       "      <td>4</td>\n",
       "      <td>1429</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>[No author name available]</td>\n",
       "      <td>[No author id available]</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>ACM International Conference Proceeding Series</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>10.1142/9789811235825_0003</td>\n",
       "      <td>...</td>\n",
       "      <td>21945357</td>\n",
       "      <td>9781799832591; 9781799832577</td>\n",
       "      <td>JEBUD</td>\n",
       "      <td>English</td>\n",
       "      <td>ACM Int. Conf. Proc. Ser.</td>\n",
       "      <td>Article</td>\n",
       "      <td>Final</td>\n",
       "      <td>All Open Access, Gold</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>2-s2.0-85138806241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>93</td>\n",
       "      <td>95</td>\n",
       "      <td>322</td>\n",
       "      <td>4</td>\n",
       "      <td>158</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>3395</td>\n",
       "      <td>93</td>\n",
       "      <td>1770</td>\n",
       "      <td>3241</td>\n",
       "      <td>278</td>\n",
       "      <td>3400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Authors              Author(s) ID         Title  \\\n",
       "count                         3400                      3399          3400   \n",
       "unique                        3167                      3156          3389   \n",
       "top     [No author name available]  [No author id available]  Introduction   \n",
       "freq                            58                        58             4   \n",
       "\n",
       "                                          Source title Volume Issue Art. No.  \\\n",
       "count                                             3400   2320  1426     1051   \n",
       "unique                                            1455    495    81     1023   \n",
       "top     ACM International Conference Proceeding Series      8     1        8   \n",
       "freq                                                93     95   322        4   \n",
       "\n",
       "       Page start Page end                         DOI  ...      ISSN  \\\n",
       "count        2336     2326                        2972  ...      2540   \n",
       "unique       1013     1369                        2969  ...       949   \n",
       "top             1       20  10.1142/9789811235825_0003  ...  21945357   \n",
       "freq          158       11                           2  ...        53   \n",
       "\n",
       "                                ISBN  CODEN Language of Original Document  \\\n",
       "count                           1174    276                          3400   \n",
       "unique                           821    124                             4   \n",
       "top     9781799832591; 9781799832577  JEBUD                       English   \n",
       "freq                              15     15                          3395   \n",
       "\n",
       "         Abbreviated Source Title Document Type Publication Stage  \\\n",
       "count                        3396          3400              3400   \n",
       "unique                       1429            13                 2   \n",
       "top     ACM Int. Conf. Proc. Ser.       Article             Final   \n",
       "freq                           93          1770              3241   \n",
       "\n",
       "                  Open Access  Source                 EID  \n",
       "count                    1097    3400                3400  \n",
       "unique                      7       1                3400  \n",
       "top     All Open Access, Gold  Scopus  2-s2.0-85138806241  \n",
       "freq                      278    3400                   1  \n",
       "\n",
       "[4 rows x 43 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe(include='object')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Consumption; Consumption inequality; Credit co...\n",
       "1       Bank branch expansion; Financial permeation; F...\n",
       "2       Customer value; FinTech; Gamification; Marketi...\n",
       "3       Crowdfunding; Fintech; Health crowdfunding; He...\n",
       "4       Asymmetric information; Consumer credit; Exper...\n",
       "                              ...                        \n",
       "3395                                                  NaN\n",
       "3396                                                  NaN\n",
       "3397    Genetic-neural network; Short-term forecasting...\n",
       "3398    Discrimination analysis; Insider trading; Mark...\n",
       "3399    correlation dimension; KSE-100 index returns; ...\n",
       "Name: Author Keywords, Length: 3400, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Author Keywords']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['Authors', 'Author(s) ID','Title', 'Abstract','Year', 'Source title', 'Author Keywords']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 3400 entries, 0 to 3399\n",
      "Series name: Author Keywords\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "2781 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 26.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data['Author Keywords'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maart\\AppData\\Local\\Temp\\ipykernel_19344\\3149525087.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Author Keywords'] = data['Author Keywords'].astype({'Author Keywords':'string'})\n"
     ]
    }
   ],
   "source": [
    "data['Author Keywords'] = data['Author Keywords'].astype({'Author Keywords':'string'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Consumption; Consumption inequality; Credit co...\n",
       "1       Bank branch expansion; Financial permeation; F...\n",
       "2       Customer value; FinTech; Gamification; Marketi...\n",
       "3       Crowdfunding; Fintech; Health crowdfunding; He...\n",
       "4       Asymmetric information; Consumer credit; Exper...\n",
       "                              ...                        \n",
       "3395                                                 <NA>\n",
       "3396                                                 <NA>\n",
       "3397    Genetic-neural network; Short-term forecasting...\n",
       "3398    Discrimination analysis; Insider trading; Mark...\n",
       "3399    correlation dimension; KSE-100 index returns; ...\n",
       "Name: Author Keywords, Length: 3400, dtype: string"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Author Keywords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maart\\AppData\\Local\\Temp\\ipykernel_19344\\2047529099.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.dropna(inplace = True,)\n"
     ]
    }
   ],
   "source": [
    "data.dropna(inplace = True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Consumption; Consumption inequality; Credit co...\n",
       "1    Bank branch expansion; Financial permeation; F...\n",
       "2    Customer value; FinTech; Gamification; Marketi...\n",
       "3    Crowdfunding; Fintech; Health crowdfunding; He...\n",
       "4    Asymmetric information; Consumer credit; Exper...\n",
       "Name: Author Keywords, dtype: string"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Author Keywords'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    2781\n",
       "Name: Author Keywords, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Author Keywords'].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2781 [00:00<?, ?it/s]c:\\Users\\maart\\anaconda3\\lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      " 92%|█████████▏| 2561/2781 [00:02<00:00, 1240.42it/s]"
     ]
    }
   ],
   "source": [
    "# run progress bar and clean up using spacy but without some heavy parts of the pipeline\n",
    "\n",
    "clean_text = []\n",
    "\n",
    "pbar = tqdm.tqdm(total=len(data['Author Keywords']),position=0, leave=True)\n",
    "\n",
    "for text in nlp.pipe(data['Author Keywords'], disable=[\"tagger\", \"parser\", \"ner\"]):\n",
    "\n",
    "  txt = [token.lemma_.lower() for token in text \n",
    "         if token.is_alpha \n",
    "         and not token.is_stop \n",
    "         and not token.is_punct]\n",
    "\n",
    "  clean_text.append(\" \".join(txt))\n",
    "\n",
    "  pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write everything into one function that can be re-used later\n",
    "def text_prepro(texts):\n",
    "  \"\"\"\n",
    "  takes in a pandas series (1 column of a DF)\n",
    "  removes twitter stuff\n",
    "  lowercases, normalizes text\n",
    "  \"\"\"\n",
    "  texts_clean = texts.map(lambda t: prepro.clean(t))\n",
    "  clean_container = []\n",
    "\n",
    "  pbar = tqdm.tqdm(total=len(texts_clean),position=0, leave=True)\n",
    "\n",
    "  for text in nlp.pipe(texts_clean, disable=[\"tagger\", \"parser\", \"ner\"]):\n",
    "\n",
    "    txt = [token.lemma_.lower() for token in text \n",
    "          if token.is_alpha \n",
    "          and not token.is_stop \n",
    "          and not token.is_punct]\n",
    "\n",
    "    clean_container.append(\" \".join(txt))\n",
    "    pbar.update(1)\n",
    "  \n",
    "  return clean_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2781/2781 [00:01<00:00, 1466.80it/s]\n",
      "C:\\Users\\maart\\AppData\\Local\\Temp\\ipykernel_19344\\4189515260.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Author_Keywords'] = text_prepro(data['Author Keywords'])\n"
     ]
    }
   ],
   "source": [
    "# apply all prepro-pipeline to texts\n",
    "data['Author_Keywords'] = text_prepro(data['Author Keywords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess texts (we need tokens)\n",
    "tokens = []\n",
    "\n",
    "for summary in nlp.pipe(data['Author Keywords'], disable=[\"ner\"]):\n",
    "  proj_tok = [token.lemma_.lower() for token in summary \n",
    "              if token.pos_ in ['NOUN', 'PROPN', 'ADJ', 'ADV'] \n",
    "              and not token.is_stop\n",
    "              and not token.is_punct] \n",
    "  tokens.append(proj_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maart\\AppData\\Local\\Temp\\ipykernel_19344\\2173657068.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['tokens'] = tokens\n"
     ]
    }
   ],
   "source": [
    "data['tokens'] = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dictionary from the articles: dictionary\n",
    "dictionary = Dictionary(data['tokens'])\n",
    "# filter out low-frequency / high-frequency stuff, also limit the vocabulary to max 500 words, since we have a low sample size ( In the example he did, he used 1000)\n",
    "dictionary.filter_extremes(no_below=50, no_above=0.5, keep_n=1000)\n",
    "# construct corpus using this dictionary\n",
    "corpus = [dictionary.doc2bow(doc) for doc in data['tokens']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing UML packages\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_matrix =tfidf.fit_transform(data['Author Keywords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import nmf\n",
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using 4 components in order to determine relevancy\n",
    "nmf = NMF(n_components=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_nmf = nmf.fit_transform(sparse_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_nmf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Author Keywords'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_nmf = matrix_nmf.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_nmf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\maart\\OneDrive\\Skrivebord\\M2\\Module-2\\Sparse nmf.ipynb Cell 37\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/maart/OneDrive/Skrivebord/M2/Module-2/Sparse%20nmf.ipynb#Y222sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m lda_model \u001b[39m=\u001b[39m LdaMulticore(corpus, id2word\u001b[39m=\u001b[39mdictionary, num_topics\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, workers \u001b[39m=\u001b[39m \u001b[39m4\u001b[39m, passes\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/maart/OneDrive/Skrivebord/M2/Module-2/Sparse%20nmf.ipynb#Y222sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m dist \u001b[39m=\u001b[39m []\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/maart/OneDrive/Skrivebord/M2/Module-2/Sparse%20nmf.ipynb#Y222sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m  lda_model:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/maart/OneDrive/Skrivebord/M2/Module-2/Sparse%20nmf.ipynb#Y222sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     dist\u001b[39m.\u001b[39mappend(t)  \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/maart/OneDrive/Skrivebord/M2/Module-2/Sparse%20nmf.ipynb#Y222sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# add list to the data frame\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\maart\\anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py:1548\u001b[0m, in \u001b[0;36mLdaModel.__getitem__\u001b[1;34m(self, bow, eps)\u001b[0m\n\u001b[0;32m   1527\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, bow, eps\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1528\u001b[0m     \u001b[39m\"\"\"Get the topic distribution for the given document.\u001b[39;00m\n\u001b[0;32m   1529\u001b[0m \n\u001b[0;32m   1530\u001b[0m \u001b[39m    Wraps :meth:`~gensim.models.ldamodel.LdaModel.get_document_topics` to support an operator style call.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1546\u001b[0m \n\u001b[0;32m   1547\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1548\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_document_topics(bow, eps, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mminimum_phi_value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mper_word_topics)\n",
      "File \u001b[1;32mc:\\Users\\maart\\anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py:1353\u001b[0m, in \u001b[0;36mLdaModel.get_document_topics\u001b[1;34m(self, bow, minimum_probability, minimum_phi_value, per_word_topics)\u001b[0m\n\u001b[0;32m   1346\u001b[0m     kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\n\u001b[0;32m   1347\u001b[0m         per_word_topics\u001b[39m=\u001b[39mper_word_topics,\n\u001b[0;32m   1348\u001b[0m         minimum_probability\u001b[39m=\u001b[39mminimum_probability,\n\u001b[0;32m   1349\u001b[0m         minimum_phi_value\u001b[39m=\u001b[39mminimum_phi_value\n\u001b[0;32m   1350\u001b[0m     )\n\u001b[0;32m   1351\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply(corpus, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m-> 1353\u001b[0m gamma, phis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minference([bow], collect_sstats\u001b[39m=\u001b[39;49mper_word_topics)\n\u001b[0;32m   1354\u001b[0m topic_dist \u001b[39m=\u001b[39m gamma[\u001b[39m0\u001b[39m] \u001b[39m/\u001b[39m \u001b[39msum\u001b[39m(gamma[\u001b[39m0\u001b[39m])  \u001b[39m# normalize distribution\u001b[39;00m\n\u001b[0;32m   1356\u001b[0m document_topics \u001b[39m=\u001b[39m [\n\u001b[0;32m   1357\u001b[0m     (topicid, topicvalue) \u001b[39mfor\u001b[39;00m topicid, topicvalue \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(topic_dist)\n\u001b[0;32m   1358\u001b[0m     \u001b[39mif\u001b[39;00m topicvalue \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m minimum_probability\n\u001b[0;32m   1359\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\maart\\anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py:696\u001b[0m, in \u001b[0;36mLdaModel.inference\u001b[1;34m(self, chunk, collect_sstats)\u001b[0m\n\u001b[0;32m    694\u001b[0m epsilon \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfinfo(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype)\u001b[39m.\u001b[39meps\n\u001b[0;32m    695\u001b[0m \u001b[39mfor\u001b[39;00m d, doc \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(chunk):\n\u001b[1;32m--> 696\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39;49m(doc) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(doc[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m], integer_types):\n\u001b[0;32m    697\u001b[0m         \u001b[39m# make sure the term IDs are ints, otherwise np will get upset\u001b[39;00m\n\u001b[0;32m    698\u001b[0m         ids \u001b[39m=\u001b[39m [\u001b[39mint\u001b[39m(idx) \u001b[39mfor\u001b[39;00m idx, _ \u001b[39min\u001b[39;00m doc]\n\u001b[0;32m    699\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "lda_model = LdaMulticore(corpus, id2word=dictionary, num_topics=5, workers = 4, passes=10)\n",
    "dist = []\n",
    "\n",
    "for t in  lda_model:\n",
    "    \n",
    "    dist.append(t)  \n",
    "    \n",
    "# add list to the data frame\n",
    "data['Topic Distribution'] = dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list_topicnum = []\n",
    "for itm in range(len(data)):\n",
    "    list_topicnum.append(sorted(data['Topic Distribution'][itm], key=lambda tup: tup[1], reverse=True)[0][0])\n",
    "data['topic_num'] = list_topicnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 components are more relevant\n",
    "plt.figure(figsize=(20,3))\n",
    "sns.heatmap(pd.DataFrame(nmf.components_, columns=data['Author Keywords']), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-means and clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap.umap_ as umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_scaler = umap.UMAP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using standard scaling data\n",
    "embeddings = umap_scaler.fit_transform(matrix_nmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "clusterer = KMeans(n_clusters=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sum_of_squared_distances = []\n",
    "K = range(1,10)\n",
    "for k in K:\n",
    "    km = KMeans(n_clusters=k)\n",
    "    km = km.fit(embeddings)\n",
    "    Sum_of_squared_distances.append(km.inertia_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Elbow Method for clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(K, Sum_of_squared_distances, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Sum_of_squared_distances')\n",
    "plt.title('Elbow Method For Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_scaler_km = umap.UMAP(n_components=6)\n",
    "embeddings_km = umap_scaler.fit_transform(matrix_nmf)\n",
    "\n",
    "\n",
    "Sum_of_squared_distances = []\n",
    "K = range(1,10)\n",
    "for k in K:\n",
    "    km = KMeans(n_clusters=k)\n",
    "    km = km.fit(embeddings_km)\n",
    "    Sum_of_squared_distances.append(km.inertia_)\n",
    "\n",
    "\n",
    "plt.plot(K, Sum_of_squared_distances, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Sum_of_squared_distances')\n",
    "plt.title('Elbow Method For Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign variables some values\n",
    "clusterer = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "label = clusterer.fit_predict(embeddings)\n",
    "centroids = clusterer.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating data for clustering using an interactive map\n",
    "vis_data = pd.DataFrame(embeddings)\n",
    "\n",
    "# vis_data.columns = ['x', 'y', 'EmployeeID', 'Department']\n",
    "\n",
    "alt.Chart(vis_data).mark_circle(size=60).encode(\n",
    "    x='x',\n",
    "    y='y',\n",
    "    # tooltip=['']\n",
    ").interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assigning groups to the clusters\n",
    "\n",
    "print(label)\n",
    "df_t = pd.DataFrame(data=embeddings, columns=['x', 'y'])\n",
    "df_t['EmployeeID'] = data_hr['EmployeeID']\n",
    "df_t['Department'] = data_hr['Department']\n",
    "df_t.columns = ['x', 'y', 'EmployeeID', 'Department']\n",
    "df_t['label'] = label\n",
    "only_0 = df_t[df_t['label'] == 0]\n",
    "only_1 = df_t[df_t['label'] == 1]\n",
    "only_2 = df_t[df_t['label'] == 2]\n",
    "\n",
    "plt.scatter(only_0['x'], only_0['y'], color='blue')\n",
    "plt.scatter(only_1['x'], only_1['y'], color='red')\n",
    "plt.scatter(only_2['x'],only_2['y'], color ='green')\n",
    "df_t.info()\n",
    "df_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to scale and transform our data into numerical values since they are categorical values \n",
    "le_keywords = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['keywords_ID'] = le_keywords.fit_transform(data['Author Keywords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Title_ID'] = le_keywords.fit_transform(data['Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = np.ones(len(data), np.uint32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['keywords_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing UML packages\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learn x-y relationships (principal components) and transform\n",
    "data_to_cluster_scaled = scaler.fit_transform(data['keywords_ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Author_Keywords.value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.text_clean.value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text_clean'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Categories'].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixing the imbalances and transforming the data into numerical values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_keywords = LabelEncoder()\n",
    "le_text_clean = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Keyword_ID'] = le_keywords.fit_transform(data['Author Keywords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text_clean_ID'] = le_text_clean.fit_transform(data['text_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Categories_ID.value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.text_clean_ID.value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['Categories_ID'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from numpy.random import RandomState\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "SM = sm = SMOTENC(random_state=42, categorical_features=[18, 19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text_clean_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Categories_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we use oversampling, since the distribution of the y value is skewed \n",
    "X_train_SMOTEN, y_train_SMOTEN = sm.fit_resample(data['text_clean'], data['Categories'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set (since we have a new output variable)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['text_clean'], data['Categories'], test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate models and \"bundle up as pipeline\"\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "cls = LogisticRegression()\n",
    "\n",
    "pipe = make_pipeline(tfidf, cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train,y_train) # fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model performance on training set\n",
    "\n",
    "y_eval = pipe.predict(X_train)\n",
    "report = classification_report(y_train, y_eval)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model performance on test set\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = ['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_p = text_prepro(pd.Series(t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.predict (t1_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LdaMulticore(corpus, id2word=dictionary, num_topics=5, workers = 4, passes=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to visualize\n",
    "lda_display = pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Let's Visualize\n",
    "pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will use a coherence matrix to find out how many topics we need for topic modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = CoherenceModel(model=lda_model, corpus=corpus, coherence='u_mass')\n",
    "# coherence = cm.get_coherence()  # get coherence value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data[\"tokens\"].str.len() != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = data['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tokens.value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirichlet_dict = corpora.Dictionary(corpus)\n",
    "bow_corpus = [dirichlet_dict.doc2bow(text) for text in corpus]\n",
    "\n",
    "# Considering 1-15 topics, as the last is cut off\n",
    "num_topics = list(range(10)[1:])\n",
    "num_keywords = 15\n",
    "\n",
    "LDA_models = {}\n",
    "LDA_topics = {}\n",
    "for i in num_topics:\n",
    "    LDA_models[i] = LdaModel(corpus=bow_corpus,\n",
    "                             id2word=dirichlet_dict,\n",
    "                             num_topics=i,\n",
    "                             update_every=1,\n",
    "                             chunksize=len(bow_corpus),\n",
    "                             passes=10,\n",
    "                             alpha='auto',\n",
    "                             random_state=42)\n",
    "\n",
    "    shown_topics = LDA_models[i].show_topics(num_topics=i, \n",
    "                                             num_words=num_keywords,\n",
    "                                             formatted=False)\n",
    "    LDA_topics[i] = [[word[0] for word in topic[1]] for topic in shown_topics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(topic_1, topic_2):\n",
    "    \"\"\"\n",
    "    Derives the Jaccard similarity of two topics\n",
    "\n",
    "    Jaccard similarity:\n",
    "    - A statistic used for comparing the similarity and diversity of sample sets\n",
    "    - J(A,B) = (A ∩ B)/(A ∪ B)\n",
    "    - Goal is low Jaccard scores for coverage of the diverse elements\n",
    "    \"\"\"\n",
    "    intersection = set(topic_1).intersection(set(topic_2))\n",
    "    union = set(topic_1).union(set(topic_2))\n",
    "                    \n",
    "    return float(len(intersection))/float(len(union))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA_stability = {}\n",
    "for i in range(0, len(num_topics)-1):\n",
    "    jaccard_sims = []\n",
    "    for t1, topic1 in enumerate(LDA_topics[num_topics[i]]): # pylint: disable=unused-variable\n",
    "        sims = []\n",
    "        for t2, topic2 in enumerate(LDA_topics[num_topics[i+1]]): # pylint: disable=unused-variable\n",
    "            sims.append(jaccard_similarity(topic1, topic2))    \n",
    "        \n",
    "        jaccard_sims.append(sims)    \n",
    "    \n",
    "    LDA_stability[num_topics[i]] = jaccard_sims\n",
    "                \n",
    "mean_stabilities = [np.array(LDA_stability[i]).mean() for i in num_topics[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherences = [CoherenceModel(model=LDA_models[i], texts=corpus, dictionary=dirichlet_dict, coherence='c_v').get_coherence() for i in num_topics[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_keywords = len(coherences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coh_sta_diffs = [coherences[i] - mean_stabilities[i] for i in range(num_keywords)[:-1]] # limit topic numbers to the number of keywords\n",
    "coh_sta_max = max(coh_sta_diffs)\n",
    "coh_sta_max_idxs = [i for i, j in enumerate(coh_sta_diffs) if j == coh_sta_max]\n",
    "ideal_topic_num_index = coh_sta_max_idxs[0] # choose less topics in case there's more than one max\n",
    "ideal_topic_num = num_topics[ideal_topic_num_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "ax = sns.lineplot(x=num_topics[:-1], y=mean_stabilities, label='Average Topic Overlap')\n",
    "ax = sns.lineplot(x=num_topics[:-1], y=coherences, label='Topic Coherence')\n",
    "\n",
    "ax.axvline(x=ideal_topic_num, label='Ideal Number of Topics', color='black')\n",
    "ax.axvspan(xmin=ideal_topic_num - 1, xmax=ideal_topic_num + 1, alpha=0.5, facecolor='grey')\n",
    "\n",
    "y_max = max(max(mean_stabilities), max(coherences)) + (0.10 * max(max(mean_stabilities), max(coherences)))\n",
    "ax.set_ylim([0, y_max])\n",
    "ax.set_xlim([1, num_topics[-1]-1])\n",
    "                \n",
    "ax.axes.set_title('Model Metrics per Number of Topics', fontsize=25)\n",
    "ax.set_ylabel('Metric Level', fontsize=20)\n",
    "ax.set_xlabel('Number of Topics', fontsize=20)\n",
    "plt.legend(fontsize=20)\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, s = get_lda_topics(lda_model_sample, corpus_sample)\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "data[\"keyword_label\"] = t\n",
    "\n",
    "data[\"keyword_label_score\"] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "995406004189bc7a762cd15e0adc766b4032076a3e0cf164ca390850079b6fa1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
